{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smartaces/opencite/blob/main/opencite_starter_cookbook_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "S_8D4zlISjto"
      },
      "id": "S_8D4zlISjto"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bNrhtcEScGk"
      },
      "source": [
        "# Welcome! Let's Explore AI Citations Together!\n",
        "Welcome to the OpenCite Cookbook! This notebook is a guided tour that helps you see exactly where AI models like ChatGPT get their information. We'll walk you through, step-by-step, how to run searches and analyze the websites and articles the AI cites as its sources.\n",
        "\n",
        "Think of this notebook as a recipe. You'll run \"cells\" (the blocks of code below) one by one. Each cell has a description like this one to explain what it does. Just follow the steps in order to begin your analysis!\n",
        "\n",
        "# Connect and Learn More\n",
        "For more information about this open source project visit: [OpenCite.ai](https://opensite.ai)\n",
        "\n",
        "# Check out the full Github repo and leave a star:\n",
        "https://github.com/smartaces/opencite/tree/main\n"
      ],
      "id": "5bNrhtcEScGk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rNvNZB4ScGn"
      },
      "source": [
        "# Step 1: Install Necessary Bits and Bobs\n",
        "First, let's get your environment ready. This cell quickly installs a few key software components that the notebook needs to run searches, create interactive controls, and build reports.\n",
        "\n",
        "You only need to run this cell once each time you start a new session.\n"
      ],
      "id": "1rNvNZB4ScGn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnsKA1WEScGn"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Run once per runtime to install dependencies\n",
        "%pip install --quiet openai rich python-dotenv ipywidgets plotly\n"
      ],
      "id": "VnsKA1WEScGn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkBxk_mQScGo"
      },
      "source": [
        "# Step 2: Set Your OpenAI API Key\n",
        "To ask the AI questions, this notebook needs to connect to OpenAI using an API key. An API key is like a password that gives you access.\n",
        "\n",
        "**Goal:** Allow the notebook to communicate with OpenAI.\n",
        "**Action:**\n",
        "1.  Get your API key from OpenAI's website: [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys).\n",
        "2.  In the file browser, copy the `.env.example` file and rename the copy to `.env`.\n",
        "3.  Paste your key into the `.env` file and save it.\n",
        "4.  Run this cell.\n",
        "\n",
        "*Note: Running searches uses the OpenAI API, which may have associated costs. You can set usage limits in your OpenAI account dashboard.*\n"
      ],
      "id": "qkBxk_mQScGo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaDnutMTScGp"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "except ImportError:  # Not running inside Colab\n",
        "    userdata = None\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "def configure_openai(secret_name: str = \"openai_key\", env_var: str = \"OPENAI_API_KEY\") -> None:\n",
        "    \"\"\"Load the OpenAI API key from Colab secrets, .env, or environment vars.\"\"\"\n",
        "    key = None\n",
        "\n",
        "    if userdata is not None:\n",
        "        try:\n",
        "            key = userdata.get(secret_name)\n",
        "            if key:\n",
        "                print(f\"‚úÖ Loaded OpenAI key from Colab secret '{secret_name}'.\")\n",
        "        except Exception as exc:  # pragma: no cover - best effort logging\n",
        "            print(f\"‚ö†Ô∏è Could not read Colab secret '{secret_name}': {exc}\")\n",
        "\n",
        "    if not key:\n",
        "        key = os.getenv(env_var)\n",
        "        if key:\n",
        "            print(f\"‚úÖ Loaded OpenAI key from environment variable '{env_var}'.\")\n",
        "\n",
        "    if not key:\n",
        "        raise RuntimeError(\n",
        "            \"OpenAI API key not found. In Colab, add it via Settings ‚Üí Secrets as 'openai_key'. \"\n",
        "            \"Locally, set OPENAI_API_KEY in a .env file or export it before running this cell.\"\n",
        "        )\n",
        "\n",
        "    os.environ[env_var] = key\n",
        "    print(\"üîê OPENAI_API_KEY is configured for this session.\")\n",
        "\n",
        "\n",
        "configure_openai()\n"
      ],
      "id": "CaDnutMTScGp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o35VOHP_ScGp"
      },
      "source": [
        "# Step 3: Choose a Project Folder\n",
        "All the data, logs, and reports you generate need a place to live. This cell will ask you to choose a central \"project folder\" (also called a workspace) where everything will be saved.\n",
        "\n",
        "If you are using Google Colab, selecting a folder in your Google Drive is a great way to make sure your work is saved.\n"
      ],
      "id": "o35VOHP_ScGp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jja4vlsxScGp"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "except ImportError:  # Not running inside Colab\n",
        "    drive = None\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "\n",
        "def configure_workspace(default_folder: str = \"opencite_workspace\") -> None:\n",
        "    \"\"\"Guide the user through selecting a workspace directory.\"\"\"\n",
        "    global WORKSPACE_ROOT\n",
        "\n",
        "    if IN_COLAB:\n",
        "        print(\"Select where you want to store project files:\")\n",
        "        print(\"  1 - Temporary Colab storage (/content)\")\n",
        "        print(\"  2 - Google Drive (/content/drive/MyDrive)\")\n",
        "        print(\"  3 - Custom absolute path\")\n",
        "        choice = input(\"Enter 1, 2, or 3 [default 1]: \").strip() or \"1\"\n",
        "\n",
        "        if choice == \"2\":\n",
        "            if drive is None:\n",
        "                raise RuntimeError(\"google.colab.drive is unavailable in this environment.\")\n",
        "            mount_point = \"/content/drive\"\n",
        "            if not Path(mount_point).exists() or not os.path.ismount(mount_point):\n",
        "                print(\"üîå Mounting Google Drive...\")\n",
        "                drive.mount(mount_point)\n",
        "            base_path = Path(mount_point) / \"MyDrive\"\n",
        "        elif choice == \"3\":\n",
        "            base_input = input(\"Enter the full path you want to use: \").strip()\n",
        "            if not base_input:\n",
        "                raise RuntimeError(\"No path provided.\")\n",
        "            base_path = Path(base_input).expanduser()\n",
        "        else:\n",
        "            base_path = Path(\"/content\")\n",
        "    else:\n",
        "        default_base = Path.cwd()\n",
        "        prompt = f\"Enter workspace path [{default_base}]: \"\n",
        "        base_input = input(prompt).strip()\n",
        "        base_path = Path(base_input).expanduser() if base_input else default_base\n",
        "\n",
        "    folder_name = input(f\"Folder name inside {base_path} [{default_folder}]: \").strip() or default_folder\n",
        "    workspace_path = base_path / folder_name\n",
        "    workspace_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    WORKSPACE_ROOT = workspace_path.resolve()\n",
        "    os.environ[\"WORKSPACE_ROOT\"] = str(WORKSPACE_ROOT)\n",
        "    print(f\"üìÅ Workspace ready at: {WORKSPACE_ROOT}\")\n",
        "\n",
        "\n",
        "configure_workspace()\n"
      ],
      "id": "Jja4vlsxScGp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFHKJkVyScGq"
      },
      "source": [
        "# Step 4: Organize Your Project Folder's Structure\n",
        "Now that you've chosen a main project folder, this cell will create a few subfolders inside it to keep your work organized (for example, a `csv_output` folder for your reports).\n",
        "\n",
        "This ensures the notebook always knows where to find and save your files.\n"
      ],
      "id": "EFHKJkVyScGq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygpHEt6QScGq"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "if \"WORKSPACE_ROOT\" in globals():\n",
        "    workspace_root = Path(WORKSPACE_ROOT)\n",
        "else:\n",
        "    env_root = os.environ.get(\"WORKSPACE_ROOT\")\n",
        "    if not env_root:\n",
        "        raise RuntimeError(\"Workspace not configured. Run the previous cell first to select a location.\")\n",
        "    workspace_root = Path(env_root)\n",
        "\n",
        "workspace_root = workspace_root.expanduser().resolve()\n",
        "os.environ[\"WORKSPACE_ROOT\"] = str(workspace_root)\n",
        "\n",
        "subfolders = {\n",
        "    \"search_results\": workspace_root / \"search_results\",\n",
        "    \"extracted_raw\": workspace_root / \"extracted_raw\",\n",
        "    \"csv_output\": workspace_root / \"csv_output\",\n",
        "    \"grabbed\": workspace_root / \"grabbed\",\n",
        "    \"terms_lists\": workspace_root / \"terms_lists\",\n",
        "    \"logs\": workspace_root / \"logs\"\n",
        "}\n",
        "\n",
        "for path in subfolders.values():\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "PATHS = {name: str(path) for name, path in subfolders.items()}\n",
        "\n",
        "config = {\n",
        "    \"workspace_root\": str(workspace_root),\n",
        "    \"paths\": PATHS\n",
        "}\n",
        "\n",
        "config_path = workspace_root / \"workspace_config.json\"\n",
        "with open(config_path, \"w\", encoding=\"utf-8\") as fp:\n",
        "    json.dump(config, fp, indent=2)\n",
        "\n",
        "os.environ[\"WORKSPACE_CONFIG\"] = str(config_path)\n",
        "\n",
        "print(f\"üìÅ Workspace root: {workspace_root}\")\n",
        "for name, path in PATHS.items():\n",
        "    print(f\"  ‚Ä¢ {name}: {path}\")\n",
        "print(f\"üóÇÔ∏è Config saved to: {config_path}\")\n",
        "print(\"‚ÑπÔ∏è Later cells: from pathlib import Path; PATHS.get('csv_output') etc.\")\n"
      ],
      "id": "ygpHEt6QScGq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2eRBwtNScGq"
      },
      "source": [
        "# Step 5: Automatically Save Files in the Right Place\n",
        "This is a small but mighty helper! Once you run this cell, the notebook will automatically save any files you create (like CSV reports) into the correct subfolder within your project folder.\n",
        "\n",
        "It's a \"set it and forget it\" step that keeps your workspace tidy without you having to worry about it.\n"
      ],
      "id": "a2eRBwtNScGq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrH0LS79ScGq"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import builtins\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "CONFIG_PATH = Path(os.environ.get(\"WORKSPACE_CONFIG\", \"\"))\n",
        "if not CONFIG_PATH.is_file():\n",
        "    raise RuntimeError(\"workspace_config.json not found. Run the setup cells first.\")\n",
        "\n",
        "with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as fp:\n",
        "    workspace_config = json.load(fp)\n",
        "\n",
        "WORKSPACE_ROOT = Path(workspace_config[\"workspace_root\"])\n",
        "PATHS = {key: Path(value) for key, value in workspace_config[\"paths\"].items()}\n",
        "\n",
        "_original_open = builtins.open\n",
        "\n",
        "\n",
        "def smart_open(file, *args, **kwargs):\n",
        "    \"\"\"Resolve relative file paths into the workspace automatically.\"\"\"\n",
        "    file_path = Path(file)\n",
        "    if not file_path.is_absolute():\n",
        "        for prefix in PATHS.values():\n",
        "            # If the path already includes a known folder name, leave as-is\n",
        "            pass\n",
        "        # Default: put file under workspace root\n",
        "        file_path = WORKSPACE_ROOT / file_path\n",
        "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    return _original_open(file_path, *args, **kwargs)\n",
        "\n",
        "\n",
        "builtins.open = smart_open\n",
        "\n",
        "print(\"‚úÖ Smart file handling enabled. Relative paths are rooted at:\")\n",
        "print(f\"   {WORKSPACE_ROOT}\")\n",
        "for name, path in PATHS.items():\n",
        "    print(f\"   ‚Ä¢ {name}: {path}\")\n"
      ],
      "id": "BrH0LS79ScGq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SjF65wxScGr"
      },
      "source": [
        "# Step 6: Enable Searches from Specific Locations\n",
        "Did you know that search results can change for users in different cities or countries? This cell prepares a tool that lets you simulate searches from specific locations.\n",
        "\n",
        "After running this, you'll be able to use the location feature in the search interfaces below.\n"
      ],
      "id": "_SjF65wxScGr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBZYwxUVScGr"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def format_location(country: str = \"US\", city: str = \"New York\", region: str = \"New York\") -> dict:\n",
        "    \"\"\"Return a location dict compatible with OpenAI web search requests.\"\"\"\n",
        "    return {\n",
        "        \"country\": country,\n",
        "        \"city\": city,\n",
        "        \"region\": region\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"‚úÖ format_location helper ready (use it when passing user_location to search calls).\")\n"
      ],
      "id": "oBZYwxUVScGr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTJvyOJ9ScGr"
      },
      "source": [
        "# Step 7: Get the AI Search Agent Ready\n",
        "It's time to prepare the \"brains\" of our operation. This cell initializes the AI Search Agent, which is responsible for sending your questions to the model and retrieving the answers along with their cited sources.\n",
        "\n",
        "Run this to bring the agent online.\n"
      ],
      "id": "LTJvyOJ9ScGr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlRou2eQScGr"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "\n",
        "class OpenAISearchAgent:\n",
        "    \"\"\"OpenAI Web Search Agent using the Responses API.\"\"\"\n",
        "\n",
        "    def __init__(self, client: OpenAI, model: str = \"gpt-5\"):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.conversation_history: List[Dict[str, Any]] = []\n",
        "        self.last_response_id: Optional[str] = None  # For GPT-5 reasoning continuity\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        query: str,\n",
        "        search_context_size: str = \"medium\",\n",
        "        user_location: Optional[Dict[str, str]] = None,\n",
        "        force_search: bool = False,\n",
        "        reasoning_effort: str = \"low\",\n",
        "        verbosity: str = \"medium\",\n",
        "        use_previous_reasoning: bool = True,\n",
        "    ) -> Dict[str, Any]:\n",
        "        tools: List[Dict[str, Any]] = []\n",
        "        web_search_config: Dict[str, Any] = {\"type\": \"web_search_preview\"}\n",
        "\n",
        "        if self.model not in [\"o3\", \"o3-pro\", \"o4-mini\"]:\n",
        "            web_search_config[\"search_context_size\"] = search_context_size\n",
        "\n",
        "        if user_location:\n",
        "            web_search_config[\"user_location\"] = {\n",
        "                \"type\": \"approximate\",\n",
        "                **user_location,\n",
        "            }\n",
        "\n",
        "        tools.append(web_search_config)\n",
        "\n",
        "        request_params: Dict[str, Any] = {\n",
        "            \"model\": self.model,\n",
        "            \"tools\": tools,\n",
        "            \"input\": query,\n",
        "        }\n",
        "\n",
        "        if self.model.startswith(\"gpt-5\"):\n",
        "            if reasoning_effort == \"minimal\":\n",
        "                reasoning_effort = \"low\"\n",
        "\n",
        "            request_params[\"reasoning\"] = {\"effort\": reasoning_effort}\n",
        "            request_params[\"text\"] = {\"verbosity\": verbosity}\n",
        "\n",
        "            if use_previous_reasoning and self.last_response_id:\n",
        "                request_params[\"previous_response_id\"] = self.last_response_id\n",
        "\n",
        "        if force_search:\n",
        "            request_params[\"tool_choice\"] = {\"type\": \"web_search_preview\"}\n",
        "\n",
        "        try:\n",
        "            response = self.client.responses.create(**request_params)\n",
        "            if hasattr(response, \"id\"):\n",
        "                self.last_response_id = response.id\n",
        "            self.conversation_history.append({\"query\": query, \"response\": response})\n",
        "            return response\n",
        "        except Exception as exc:  # pragma: no cover - API/network errors\n",
        "            return {\"error\": str(exc)}\n",
        "\n",
        "    def extract_text_response(self, response: Any) -> str:\n",
        "        try:\n",
        "            if isinstance(response, dict) and \"error\" in response:\n",
        "                return f\"Error: {response['error']}\"\n",
        "            if hasattr(response, \"output_text\"):\n",
        "                return response.output_text\n",
        "            if hasattr(response, \"output\"):\n",
        "                for output in response.output:\n",
        "                    if getattr(output, \"type\", None) == \"message\" and hasattr(output, \"content\"):\n",
        "                        for item in output.content:\n",
        "                            if getattr(item, \"type\", None) == \"output_text\":\n",
        "                                return getattr(item, \"text\", \"\")\n",
        "                    elif isinstance(output, dict) and output.get(\"type\") == \"message\":\n",
        "                        for item in output.get(\"content\", []):\n",
        "                            if item.get(\"type\") == \"output_text\":\n",
        "                                return item.get(\"text\", \"\")\n",
        "            return \"No text response found\"\n",
        "        except Exception as exc:\n",
        "            return f\"Error extracting response: {exc}\"\n",
        "\n",
        "    def extract_citations(self, response: Any) -> List[Dict[str, Any]]:\n",
        "        citations: List[Dict[str, Any]] = []\n",
        "        try:\n",
        "            if hasattr(response, \"output\"):\n",
        "                for output in response.output:\n",
        "                    if getattr(output, \"type\", None) == \"message\" and hasattr(output, \"content\"):\n",
        "                        for item in output.content:\n",
        "                            if getattr(item, \"type\", None) == \"output_text\":\n",
        "                                annotations = getattr(item, \"annotations\", [])\n",
        "                                for ann in annotations:\n",
        "                                    if getattr(ann, \"type\", None) == \"url_citation\":\n",
        "                                        citations.append({\n",
        "                                            \"url\": getattr(ann, \"url\", \"\"),\n",
        "                                            \"title\": getattr(ann, \"title\", \"\"),\n",
        "                                        })\n",
        "                    elif isinstance(output, dict) and output.get(\"type\") == \"message\":\n",
        "                        for item in output.get(\"content\", []):\n",
        "                            if item.get(\"type\") == \"output_text\":\n",
        "                                for ann in item.get(\"annotations\", []):\n",
        "                                    if ann.get(\"type\") == \"url_citation\":\n",
        "                                        citations.append({\n",
        "                                            \"url\": ann.get(\"url\", \"\"),\n",
        "                                            \"title\": ann.get(\"title\", \"\"),\n",
        "                                        })\n",
        "        except Exception:\n",
        "            pass\n",
        "        return citations\n",
        "\n",
        "    def get_search_actions(self, response: Any) -> List[Dict[str, Any]]:\n",
        "        actions: List[Dict[str, Any]] = []\n",
        "        try:\n",
        "            if hasattr(response, \"output\"):\n",
        "                for output in response.output:\n",
        "                    if getattr(output, \"type\", None) == \"web_search_call\":\n",
        "                        actions.append({\n",
        "                            \"id\": getattr(output, \"id\", \"\"),\n",
        "                            \"status\": getattr(output, \"status\", \"\"),\n",
        "                            \"action\": getattr(output, \"action\", {}),\n",
        "                        })\n",
        "                    elif isinstance(output, dict) and output.get(\"type\") == \"web_search_call\":\n",
        "                        actions.append({\n",
        "                            \"id\": output.get(\"id\", \"\"),\n",
        "                            \"status\": output.get(\"status\", \"\"),\n",
        "                            \"action\": output.get(\"action\", {}),\n",
        "                        })\n",
        "        except Exception:\n",
        "            pass\n",
        "        return actions\n",
        "\n",
        "    def clear_history(self) -> None:\n",
        "        self.conversation_history = []\n",
        "        self.last_response_id = None\n",
        "        print(\"üóëÔ∏è Conversation history cleared\")\n",
        "\n",
        "\n",
        "search_agent = OpenAISearchAgent(client, model=\"gpt-5\")\n",
        "print(f\"ü§ñ Search Agent initialized with {search_agent.model}!\")\n",
        "print(\"üí° Tip: GPT-5 reasoning chains persist across turns when previous_response_id is set.\")\n",
        "\n",
        "\n",
        "def print_search_result(response, show_citations: bool = True, show_actions: bool = False) -> None:\n",
        "    \"\"\"Pretty-print a response from the search agent.\"\"\"\n",
        "    text = search_agent.extract_text_response(response)\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üìù RESPONSE:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(text)\n",
        "    print()\n",
        "\n",
        "    if show_citations:\n",
        "        citations = search_agent.extract_citations(response)\n",
        "        if citations:\n",
        "            print(\"=\" * 80)\n",
        "            print(\"üîó CITATIONS:\")\n",
        "            print(\"=\" * 80)\n",
        "            for i, cite in enumerate(citations, 1):\n",
        "                print(f\"{i}. {cite.get('title', 'Untitled')}\")\n",
        "                print(f\"   URL: {cite.get('url', 'Unknown')}\")\n",
        "                print()\n",
        "\n",
        "    if show_actions:\n",
        "        actions = search_agent.get_search_actions(response)\n",
        "        if actions:\n",
        "            print(\"=\" * 80)\n",
        "            print(\"üîç SEARCH ACTIONS:\")\n",
        "            print(\"=\" * 80)\n",
        "            for action in actions:\n",
        "                print(f\"ID: {action.get('id', '')}\")\n",
        "                print(f\"Status: {action.get('status', '')}\")\n",
        "                if action.get('action'):\n",
        "                    print(f\"Action details: {action['action']}\")\n",
        "                print()\n"
      ],
      "id": "hlRou2eQScGr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-Gh_UFIScGr"
      },
      "source": [
        "# Step 8: Prepare the Tool that Logs Your Results\n",
        "To analyze your search results, you first need to record them. This cell gets the data logging tool ready. It will automatically save every search you run into organized data files (CSVs), which are used to build the final analysis reports.\n"
      ],
      "id": "O-Gh_UFIScGr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgYh5RLGScGr"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Iterable, Optional\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class ReportHelper:\n",
        "    \"\"\"Consistent logging/serialization for notebook cells.\"\"\"\n",
        "\n",
        "    DETAIL_COLUMNS: Iterable[str] = [\n",
        "        \"row_timestamp\",\n",
        "        \"scenario\",\n",
        "        \"execution_id\",\n",
        "        \"unit_id\",\n",
        "        \"turn_or_run\",\n",
        "        \"role\",\n",
        "        \"model\",\n",
        "        \"persona_profile\",\n",
        "        \"persona_model\",\n",
        "        \"query_or_topic\",\n",
        "        \"message_text\",\n",
        "        \"citation_rank\",\n",
        "        \"citation_title\",\n",
        "        \"citation_url\",\n",
        "        \"domain\",\n",
        "        \"context\",\n",
        "        \"reasoning\",\n",
        "        \"location_country\",\n",
        "        \"location_city\",\n",
        "        \"location_region\",\n",
        "        \"response_file\",\n",
        "    ]\n",
        "\n",
        "    def __init__(self, scenario: str, paths: Dict[str, Any]):\n",
        "        self.scenario = scenario\n",
        "        self.paths = paths\n",
        "        self.output_dir = Path(paths[\"csv_output\"]).expanduser().resolve()\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.raw_dir = self.output_dir / \"raw\"\n",
        "        self.raw_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.execution_id = f\"{timestamp}_{uuid.uuid4().hex[:8]}\"\n",
        "        self.start_ts = datetime.now().isoformat()\n",
        "        self._detail_rows: list[Dict[str, Any]] = []\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    def save_raw_response(self, label: str, response: Any) -> Path:\n",
        "        \"\"\"Persist raw response JSON and return the file path.\"\"\"\n",
        "        raw_path = self.raw_dir / f\"{self.scenario}_{self.execution_id}_{label}.json\"\n",
        "        try:\n",
        "            payload = response.model_dump()  # type: ignore[attr-defined]\n",
        "        except AttributeError:\n",
        "            payload = response\n",
        "        raw_path.write_text(json.dumps(payload, indent=2, default=str))\n",
        "        return raw_path\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    def add_detail_row(self, **row: Any) -> None:\n",
        "        \"\"\"Append a single detail row (with default metadata) to the log.\"\"\"\n",
        "        row.setdefault(\"row_timestamp\", datetime.now().isoformat())\n",
        "        row.setdefault(\"scenario\", self.scenario)\n",
        "        row.setdefault(\"execution_id\", self.execution_id)\n",
        "        for column in self.DETAIL_COLUMNS:\n",
        "            row.setdefault(column, None)\n",
        "        self._detail_rows.append(row)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    def write_detail_csv(self) -> Path:\n",
        "        \"\"\"Flush accumulated detail rows to CSV and return the path.\"\"\"\n",
        "        detail_path = self.output_dir / f\"{self.scenario}_detail_{self.execution_id}.csv\"\n",
        "        df = pd.DataFrame(self._detail_rows)\n",
        "        # Reorder columns if possible\n",
        "        cols = [c for c in self.DETAIL_COLUMNS if c in df.columns]\n",
        "        rest = [c for c in df.columns if c not in cols]\n",
        "        df = df[cols + rest]\n",
        "        df.to_csv(detail_path, index=False)\n",
        "        return detail_path\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    def write_summary_csv(self, summary_row: Dict[str, Any]) -> Path:\n",
        "        \"\"\"Write a one-row summary CSV.\"\"\"\n",
        "        summary_row.setdefault(\"scenario\", self.scenario)\n",
        "        summary_row.setdefault(\"execution_id\", self.execution_id)\n",
        "        summary_row.setdefault(\"timestamp\", datetime.now().isoformat())\n",
        "        summary_path = self.output_dir / f\"{self.scenario}_summary_{self.execution_id}.csv\"\n",
        "        pd.DataFrame([summary_row]).to_csv(summary_path, index=False)\n",
        "        return summary_path\n"
      ],
      "id": "YgYh5RLGScGr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4wDVuwzScGs"
      },
      "source": [
        "# Search Mode 1: Ask a Single Question\n",
        "Use this mode for a quick, one-off search. It's the fastest way to ask a question and see the sources behind the answer. Simply type your query, choose your settings, and get an immediate report on the citations.\n"
      ],
      "id": "c4wDVuwzScGs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcAu043UScGs"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from urllib.parse import urlparse\n",
        "from pathlib import Path\n",
        "import json\n",
        "import os\n",
        "\n",
        "if 'PATHS' not in globals():\n",
        "    config_path = Path(os.environ.get('WORKSPACE_CONFIG', ''))\n",
        "    if not config_path.is_file():\n",
        "        raise RuntimeError('Workspace not configured. Run the setup cells first.')\n",
        "    with open(config_path, 'r', encoding='utf-8') as fp:\n",
        "        workspace_config = json.load(fp)\n",
        "    PATHS = {k: Path(v) for k, v in workspace_config['paths'].items()}\n",
        "\n",
        "if 'search_agent' not in globals():\n",
        "    raise RuntimeError('Search agent not initialized. Run the agent cell first.')\n",
        "\n",
        "if 'ReportHelper' not in globals():\n",
        "    raise RuntimeError('ReportHelper not defined. Run the reporting helper cell first.')\n",
        "\n",
        "# --- Query & model controls ---\n",
        "query_input = widgets.Textarea(\n",
        "    value=\"What is the best value smartphone in 2026 for $1000\",\n",
        "    description=\"Query:\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"80px\"),\n",
        "    placeholder=\"Type your search question...\"\n",
        ")\n",
        "\n",
        "context_dropdown = widgets.Dropdown(\n",
        "    options=[(\"Low\", \"low\"), (\"Medium\", \"medium\"), (\"High\", \"high\")],\n",
        "    value=\"medium\",\n",
        "    description=\"Context:\",\n",
        ")\n",
        "\n",
        "reasoning_dropdown = widgets.Dropdown(\n",
        "    options=[(\"Low\", \"low\"), (\"Medium\", \"medium\"), (\"High\", \"high\")],\n",
        "    value=\"low\",\n",
        "    description=\"Reasoning:\",\n",
        ")\n",
        "\n",
        "# --- Location controls ---\n",
        "location_toggle = widgets.Checkbox(value=False, description=\"Apply location bias\")\n",
        "\n",
        "location_presets = widgets.Dropdown(\n",
        "    options=[\n",
        "        (\"US ¬∑ New York\", \"us_ny\"),\n",
        "        (\"UK ¬∑ London\", \"uk_london\"),\n",
        "        (\"US ¬∑ San Francisco\", \"us_sf\"),\n",
        "        (\"France ¬∑ Paris\", \"fr_paris\"),\n",
        "        (\"Germany ¬∑ Berlin\", \"de_berlin\"),\n",
        "        (\"Custom\", \"custom\"),\n",
        "    ],\n",
        "    value=\"us_ny\",\n",
        "    description=\"Preset:\",\n",
        "    disabled=True,\n",
        ")\n",
        "\n",
        "custom_country = widgets.Text(value=\"US\", description=\"Country:\", disabled=True)\n",
        "custom_city = widgets.Text(value=\"New York\", description=\"City:\", disabled=True)\n",
        "custom_region = widgets.Text(value=\"New York\", description=\"Region:\", disabled=True)\n",
        "\n",
        "run_button = widgets.Button(description=\"Run Search\", button_style=\"primary\", icon=\"search\")\n",
        "output = widgets.Output()\n",
        "\n",
        "preset_map = {\n",
        "    \"us_ny\": (\"US\", \"New York\", \"New York\"),\n",
        "    \"uk_london\": (\"GB\", \"London\", \"London\"),\n",
        "    \"us_sf\": (\"US\", \"San Francisco\", \"California\"),\n",
        "    \"fr_paris\": (\"FR\", \"Paris\", \"√éle-de-France\"),\n",
        "    \"de_berlin\": (\"DE\", \"Berlin\", \"Berlin\"),\n",
        "}\n",
        "\n",
        "\n",
        "def update_location_visibility(change=None):\n",
        "    enabled = location_toggle.value\n",
        "    location_presets.disabled = not enabled\n",
        "    is_custom = enabled and location_presets.value == \"custom\"\n",
        "    for widget in (custom_country, custom_city, custom_region):\n",
        "        widget.disabled = not is_custom\n",
        "\n",
        "\n",
        "def get_location_dict():\n",
        "    if not location_toggle.value:\n",
        "        return None\n",
        "    if location_presets.value != \"custom\":\n",
        "        country, city, region = preset_map[location_presets.value]\n",
        "    else:\n",
        "        country = custom_country.value or \"US\"\n",
        "        city = custom_city.value or \"New York\"\n",
        "        region = custom_region.value or city\n",
        "    return format_location(country=country, city=city, region=region)\n",
        "\n",
        "\n",
        "location_toggle.observe(update_location_visibility, \"value\")\n",
        "location_presets.observe(update_location_visibility, \"value\")\n",
        "update_location_visibility()\n",
        "\n",
        "\n",
        "def run_single_search(_):\n",
        "    query = query_input.value.strip()\n",
        "    with output:\n",
        "        clear_output()\n",
        "        if not query:\n",
        "            print(\"‚ö†Ô∏è Please enter a query before running the search.\")\n",
        "            return\n",
        "        user_location = get_location_dict()\n",
        "        location_note = (\n",
        "            f\"üìç Location bias: {user_location}\" if user_location else \"üìç Location bias: none\"\n",
        "        )\n",
        "        reporter = ReportHelper('single_run', PATHS)\n",
        "        execution_id = reporter.execution_id\n",
        "        model_name = getattr(search_agent, 'model', 'unknown')\n",
        "        print(f\"‚ñ∂ Execution ID: {execution_id}\")\n",
        "        print(\"‚è≥ Running search, hang tight...\\n\")\n",
        "        reporter.add_detail_row(\n",
        "            unit_id=f\"{execution_id}_query\",\n",
        "            turn_or_run=0,\n",
        "            role='user',\n",
        "            model=None,\n",
        "            query_or_topic=query,\n",
        "            message_text=query,\n",
        "            citation_rank=None,\n",
        "            citation_title=None,\n",
        "            citation_url=None,\n",
        "            domain=None,\n",
        "            context=context_dropdown.value,\n",
        "            reasoning=reasoning_dropdown.value,\n",
        "            location_country=user_location['country'] if user_location else None,\n",
        "            location_city=user_location['city'] if user_location else None,\n",
        "            location_region=user_location['region'] if user_location else None,\n",
        "            response_file=None,\n",
        "        )\n",
        "        response = search_agent.search(\n",
        "            query,\n",
        "            search_context_size=context_dropdown.value,\n",
        "            reasoning_effort=reasoning_dropdown.value,\n",
        "            verbosity=\"medium\",\n",
        "            user_location=user_location,\n",
        "        )\n",
        "        raw_path = reporter.save_raw_response(\"run\", response)\n",
        "        text = search_agent.extract_text_response(response)\n",
        "        citations = search_agent.extract_citations(response) or []\n",
        "        if citations:\n",
        "            for rank, cite in enumerate(citations, 1):\n",
        "                url = cite.get('url', '')\n",
        "                domain = urlparse(url).netloc.replace('www.', '') if url else ''\n",
        "                reporter.add_detail_row(\n",
        "                    unit_id=f\"{execution_id}_advisor_{rank}\",\n",
        "                    turn_or_run=1,\n",
        "                    role='AI System',\n",
        "                    model=model_name,\n",
        "                    query_or_topic=query,\n",
        "                    message_text=text,\n",
        "                    citation_rank=rank,\n",
        "                    citation_title=cite.get('title', ''),\n",
        "                    citation_url=url,\n",
        "                    domain=domain,\n",
        "                    context=context_dropdown.value,\n",
        "                    reasoning=reasoning_dropdown.value,\n",
        "                    location_country=user_location['country'] if user_location else None,\n",
        "                    location_city=user_location['city'] if user_location else None,\n",
        "                    location_region=user_location['region'] if user_location else None,\n",
        "                    response_file=str(raw_path),\n",
        "                )\n",
        "        else:\n",
        "            reporter.add_detail_row(\n",
        "                unit_id=f\"{execution_id}_advisor_1\",\n",
        "                turn_or_run=1,\n",
        "                role='AI System',\n",
        "                model=model_name,\n",
        "                query_or_topic=query,\n",
        "                message_text=text,\n",
        "                citation_rank=None,\n",
        "                citation_title=None,\n",
        "                citation_url=None,\n",
        "                domain=None,\n",
        "                context=context_dropdown.value,\n",
        "                reasoning=reasoning_dropdown.value,\n",
        "                location_country=user_location['country'] if user_location else None,\n",
        "                location_city=user_location['city'] if user_location else None,\n",
        "                location_region=user_location['region'] if user_location else None,\n",
        "                response_file=str(raw_path),\n",
        "            )\n",
        "        detail_path = reporter.write_detail_csv()\n",
        "        summary_row = {\n",
        "            'model': model_name,\n",
        "            'query': query,\n",
        "            'context': context_dropdown.value,\n",
        "            'reasoning': reasoning_dropdown.value,\n",
        "            'location_country': user_location['country'] if user_location else None,\n",
        "            'location_city': user_location['city'] if user_location else None,\n",
        "            'location_region': user_location['region'] if user_location else None,\n",
        "            'total_citations': len(citations),\n",
        "            'unique_citation_urls': len({c.get('url') for c in citations if c.get('url')}) if citations else 0,\n",
        "            'unique_domains': len({urlparse(c.get('url', '')).netloc.replace('www.', '') for c in citations if c.get('url')}) if citations else 0,\n",
        "        }\n",
        "        summary_path = reporter.write_summary_csv(summary_row)\n",
        "        clear_output()\n",
        "        print(f\"üîç Query: {query}\\n{location_note}\\n\")\n",
        "        print_search_result(response)\n",
        "        print(f\"\\nüíæ Detail CSV: {detail_path}\")\n",
        "        print(f\"üíæ Summary CSV: {summary_path}\")\n",
        "\n",
        "\n",
        "run_button.on_click(run_single_search)\n",
        "\n",
        "location_box = widgets.VBox([\n",
        "    location_toggle,\n",
        "    location_presets,\n",
        "    widgets.HBox([custom_country, custom_city, custom_region]),\n",
        "])\n",
        "\n",
        "controls = widgets.VBox([\n",
        "    query_input,\n",
        "    widgets.HBox([context_dropdown, reasoning_dropdown]),\n",
        "    location_box,\n",
        "    run_button,\n",
        "])\n",
        "\n",
        "display(widgets.VBox([controls, output]))\n"
      ],
      "id": "xcAu043UScGs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLv6zhrbScGs"
      },
      "source": [
        "# Search Mode 2: Test How Often a Source is Cited\n",
        "Does the AI cite the same sources every time for the same question? This mode helps you find out. It runs the same prompt multiple times so you can see how much the results vary. This is great for understanding how stable or consistent a source's ranking is.\n"
      ],
      "id": "JLv6zhrbScGs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vSNoy3lScGs"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "if 'PATHS' not in globals():\n",
        "    config_path = Path(os.environ.get('WORKSPACE_CONFIG', ''))\n",
        "    if not config_path.is_file():\n",
        "        raise RuntimeError('Workspace not configured. Run the setup cells first.')\n",
        "    with open(config_path, 'r', encoding='utf-8') as fp:\n",
        "        workspace_config = json.load(fp)\n",
        "    PATHS = {k: Path(v) for k, v in workspace_config['paths'].items()}\n",
        "\n",
        "if 'search_agent' not in globals():\n",
        "    raise RuntimeError('Search agent not initialized. Run the agent cell first.')\n",
        "\n",
        "if 'ReportHelper' not in globals():\n",
        "    raise RuntimeError('ReportHelper not defined. Run the reporting helper cell first.')\n",
        "\n",
        "query_input_multi = widgets.Textarea(\n",
        "    value=\"Compare Samsung S25 vs Google Pixel\",\n",
        "    description=\"Query:\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"80px\"),\n",
        ")\n",
        "\n",
        "context_dropdown_multi = widgets.Dropdown(\n",
        "    options=[(\"Low\", \"low\"), (\"Medium\", \"medium\"), (\"High\", \"high\")],\n",
        "    value=\"medium\",\n",
        "    description=\"Context:\",\n",
        ")\n",
        "\n",
        "reasoning_dropdown_multi = widgets.Dropdown(\n",
        "    options=[(\"Low\", \"low\"), (\"Medium\", \"medium\"), (\"High\", \"high\")],\n",
        "    value=\"low\",\n",
        "    description=\"Reasoning:\",\n",
        ")\n",
        "\n",
        "run_count_dropdown = widgets.Dropdown(\n",
        "    options=[(\"1 run\", 1), (\"3 runs\", 3), (\"5 runs\", 5), (\"10 runs\", 10), (\"20 runs\", 20)],\n",
        "    value=3,\n",
        "    description=\"# Runs:\",\n",
        ")\n",
        "\n",
        "location_toggle_multi = widgets.Checkbox(value=False, description=\"Apply location bias\")\n",
        "location_presets_multi = widgets.Dropdown(\n",
        "    options=[\n",
        "        (\"US ¬∑ New York\", \"us_ny\"),\n",
        "        (\"UK ¬∑ London\", \"uk_london\"),\n",
        "        (\"US ¬∑ San Francisco\", \"us_sf\"),\n",
        "        (\"France ¬∑ Paris\", \"fr_paris\"),\n",
        "        (\"Germany ¬∑ Berlin\", \"de_berlin\"),\n",
        "        (\"Custom\", \"custom\"),\n",
        "    ],\n",
        "    value=\"us_ny\",\n",
        "    description=\"Preset:\",\n",
        "    disabled=True,\n",
        ")\n",
        "custom_country_multi = widgets.Text(value=\"US\", description=\"Country:\", disabled=True)\n",
        "custom_city_multi = widgets.Text(value=\"New York\", description=\"City:\", disabled=True)\n",
        "custom_region_multi = widgets.Text(value=\"New York\", description=\"Region:\", disabled=True)\n",
        "\n",
        "run_multi_button = widgets.Button(description=\"Run Multi-Search\", button_style=\"primary\", icon=\"refresh\")\n",
        "output_multi = widgets.Output()\n",
        "\n",
        "preset_map_multi = {\n",
        "    \"us_ny\": (\"US\", \"New York\", \"New York\"),\n",
        "    \"uk_london\": (\"GB\", \"London\", \"London\"),\n",
        "    \"us_sf\": (\"US\", \"San Francisco\", \"California\"),\n",
        "    \"fr_paris\": (\"FR\", \"Paris\", \"√éle-de-France\"),\n",
        "    \"de_berlin\": (\"DE\", \"Berlin\", \"Berlin\"),\n",
        "}\n",
        "\n",
        "\n",
        "def update_location_multi(change=None):\n",
        "    enabled = location_toggle_multi.value\n",
        "    location_presets_multi.disabled = not enabled\n",
        "    is_custom = enabled and location_presets_multi.value == \"custom\"\n",
        "    for widget in (custom_country_multi, custom_city_multi, custom_region_multi):\n",
        "        widget.disabled = not is_custom\n",
        "\n",
        "\n",
        "def get_location_multi():\n",
        "    if not location_toggle_multi.value:\n",
        "        return None\n",
        "    if location_presets_multi.value != \"custom\":\n",
        "        country, city, region = preset_map_multi[location_presets_multi.value]\n",
        "    else:\n",
        "        country = custom_country_multi.value or \"US\"\n",
        "        city = custom_city_multi.value or \"New York\"\n",
        "        region = custom_region_multi.value or city\n",
        "    return format_location(country=country, city=city, region=region)\n",
        "\n",
        "\n",
        "location_toggle_multi.observe(update_location_multi, \"value\")\n",
        "location_presets_multi.observe(update_location_multi, \"value\")\n",
        "update_location_multi()\n",
        "\n",
        "\n",
        "def slugify(text: str, length: int = 60) -> str:\n",
        "    slug = re.sub(r\"[^a-z0-9]+\", \"_\", text.lower()).strip(\"_\")\n",
        "    return slug[:length] or \"query\"\n",
        "\n",
        "\n",
        "def run_multi(_):\n",
        "    query = query_input_multi.value.strip()\n",
        "    run_count = run_count_dropdown.value\n",
        "    user_location = get_location_multi()\n",
        "\n",
        "    with output_multi:\n",
        "        clear_output()\n",
        "        if not query:\n",
        "            print(\"‚ö†Ô∏è Please enter a query before running the analysis.\")\n",
        "            return\n",
        "\n",
        "        reporter = ReportHelper('multi_run', PATHS)\n",
        "        execution_id = reporter.execution_id\n",
        "        model_name = getattr(search_agent, 'model', 'unknown')\n",
        "\n",
        "        print(f\"‚ñ∂ Execution ID: {execution_id}\")\n",
        "        print(f\"‚ñ∂ Running {run_count} searches for: {query}\")\n",
        "        if user_location:\n",
        "            print(f\"üìç Location bias: {user_location}\\n\")\n",
        "        else:\n",
        "            print(\"üìç Location bias: none\\n\")\n",
        "\n",
        "        summaries = []\n",
        "\n",
        "        for idx in range(1, run_count + 1):\n",
        "            run_id = f\"{execution_id}_run_{idx}\"\n",
        "            print(f\"--- Run {idx}/{run_count} ---\")\n",
        "            print(\"‚è≥ Requesting response...\\n\")\n",
        "            response = search_agent.search(\n",
        "                query,\n",
        "                search_context_size=context_dropdown_multi.value,\n",
        "                reasoning_effort=reasoning_dropdown_multi.value,\n",
        "                verbosity=\"medium\",\n",
        "                user_location=user_location,\n",
        "            )\n",
        "\n",
        "            raw_path = reporter.save_raw_response(f\"run_{idx}\", response)\n",
        "            print_search_result(response)\n",
        "            print()\n",
        "\n",
        "            text = search_agent.extract_text_response(response)\n",
        "            citations = search_agent.extract_citations(response)\n",
        "            citation_urls = []\n",
        "\n",
        "            if citations:\n",
        "                for rank, cite in enumerate(citations, 1):\n",
        "                    url = cite.get('url', '')\n",
        "                    domain = urlparse(url).netloc.replace('www.', '') if url else ''\n",
        "                    reporter.add_detail_row(\n",
        "                        unit_id=run_id,\n",
        "                        turn_or_run=idx,\n",
        "                        role='AI System',\n",
        "                        model=model_name,\n",
        "                        query_or_topic=query,\n",
        "                        message_text=text,\n",
        "                        citation_rank=rank,\n",
        "                        citation_title=cite.get('title', ''),\n",
        "                        citation_url=url,\n",
        "                        domain=domain,\n",
        "                        context=context_dropdown_multi.value,\n",
        "                        reasoning=reasoning_dropdown_multi.value,\n",
        "                        location_country=user_location['country'] if user_location else None,\n",
        "                        location_city=user_location['city'] if user_location else None,\n",
        "                        location_region=user_location['region'] if user_location else None,\n",
        "                        response_file=str(raw_path),\n",
        "                    )\n",
        "                    if url:\n",
        "                        citation_urls.append(url)\n",
        "            else:\n",
        "                reporter.add_detail_row(\n",
        "                    unit_id=run_id,\n",
        "                    turn_or_run=idx,\n",
        "                    role='AI System',\n",
        "                    model=model_name,\n",
        "                    query_or_topic=query,\n",
        "                    message_text=text,\n",
        "                    citation_rank=None,\n",
        "                    citation_title=None,\n",
        "                    citation_url=None,\n",
        "                    domain=None,\n",
        "                    context=context_dropdown_multi.value,\n",
        "                    reasoning=reasoning_dropdown_multi.value,\n",
        "                    location_country=user_location['country'] if user_location else None,\n",
        "                    location_city=user_location['city'] if user_location else None,\n",
        "                    location_region=user_location['region'] if user_location else None,\n",
        "                    response_file=str(raw_path),\n",
        "                )\n",
        "\n",
        "            summaries.append({'run': idx, 'citations': citation_urls})\n",
        "            print(f\"Run {idx} complete ‚Äî {len(citation_urls)} citations captured.\\n\")\n",
        "\n",
        "        detail_path = reporter.write_detail_csv()\n",
        "\n",
        "        df = pd.DataFrame(reporter._detail_rows)\n",
        "        df_valid = df.dropna(subset=['citation_url'])\n",
        "        citation_sets = [tuple(sorted(summary['citations'])) for summary in summaries]\n",
        "        unique_sets = len(set(citation_sets))\n",
        "        consistency_pct = 100.0 if len(citation_sets) <= 1 else 100 * (1 - (unique_sets - 1) / len(citation_sets))\n",
        "        domain_counts = df_valid['domain'].value_counts().head(5)\n",
        "\n",
        "        print(\"=== Consistency Summary ===\")\n",
        "        print(f\"Runs executed: {run_count}\")\n",
        "        print(f\"Unique citation sets: {unique_sets}\")\n",
        "        print(f\"Citation consistency score: {consistency_pct:.1f}%\\n\")\n",
        "        if not domain_counts.empty:\n",
        "            print(\"Top cited domains:\")\n",
        "            for domain, count in domain_counts.items():\n",
        "                print(f\"  ‚Ä¢ {domain}: {count}\")\n",
        "\n",
        "        summary_row = {\n",
        "            'model': model_name,\n",
        "            'query': query,\n",
        "            'run_count': run_count,\n",
        "            'context': context_dropdown_multi.value,\n",
        "            'reasoning': reasoning_dropdown_multi.value,\n",
        "            'location_country': user_location['country'] if user_location else None,\n",
        "            'location_city': user_location['city'] if user_location else None,\n",
        "            'location_region': user_location['region'] if user_location else None,\n",
        "            'total_citations': int(df_valid['citation_url'].count()),\n",
        "            'unique_citation_urls': int(df_valid['citation_url'].nunique()),\n",
        "            'unique_domains': int(df_valid['domain'].nunique()),\n",
        "            'unique_citation_sets': unique_sets,\n",
        "            'consistency_pct': consistency_pct,\n",
        "        }\n",
        "        for idx, (domain, count) in enumerate(domain_counts.items(), start=1):\n",
        "            summary_row[f\"top_domain_{idx}\"] = domain\n",
        "            summary_row[f\"top_domain_{idx}_count\"] = count\n",
        "\n",
        "        summary_path = reporter.write_summary_csv(summary_row)\n",
        "\n",
        "        print(f\"\\nüíæ Detail CSV: {detail_path}\")\n",
        "        print(f\"üíæ Summary CSV: {summary_path}\")\n",
        "\n",
        "\n",
        "run_multi_button.on_click(run_multi)\n",
        "\n",
        "location_box_multi = widgets.VBox([\n",
        "    location_toggle_multi,\n",
        "    location_presets_multi,\n",
        "    widgets.HBox([custom_country_multi, custom_city_multi, custom_region_multi]),\n",
        "])\n",
        "\n",
        "controls_multi = widgets.VBox([\n",
        "    query_input_multi,\n",
        "    widgets.HBox([context_dropdown_multi, reasoning_dropdown_multi, run_count_dropdown]),\n",
        "    location_box_multi,\n",
        "    run_multi_button,\n",
        "])\n",
        "\n",
        "display(widgets.VBox([controls_multi, output_multi]))\n"
      ],
      "id": "-vSNoy3lScGs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhLcHUFgScGt"
      },
      "source": [
        "# Search Mode 3: See How Citations Change in a Conversation\n",
        "\n",
        "This is the most advanced search mode. It lets you see how an AI's citations change over the course of a back-and-forth conversation.\n",
        "\n",
        "### How it Works\n",
        "Instead of you typing every reply, this cell **simulates a user** for you. Here‚Äôs the process:\n",
        "1.  You provide the **Starting Prompt** to kick off the conversation.\n",
        "2.  The main AI search agent provides its first response and citations.\n",
        "3.  Then, a second AI agent, acting as a curious user, reads the response and automatically generates a relevant follow-up question.\n",
        "4.  This process repeats, creating a natural conversation so you can track how the sources evolve from one turn to the next.\n",
        "\n",
        "### Key Settings\n",
        "- **Starting Prompt**: The first message that begins the conversation.\n",
        "- **Persona**: This is the most powerful feature. You can give the simulated user a personality or a goal. Are they a 'Budget college student' or a 'Travel photographer'? Choosing a persona directs the AI to ask questions relevant to that audience's interests, helping you see what sources are shown to different types of users. You can also select 'Custom' to write your own persona from scratch.\n",
        "- **Turns**: A \"turn\" is one complete back-and-forth exchange (one question from the simulated user and one response from the AI assistant). Setting this to '3' will create a three-exchange conversation.\n"
      ],
      "id": "mhLcHUFgScGt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "364Vki9iScGt"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "PERSONA_MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "if 'PATHS' not in globals():\n",
        "    config_path = Path(os.environ.get('WORKSPACE_CONFIG', ''))\n",
        "    if not config_path.is_file():\n",
        "        raise RuntimeError('Workspace not configured. Run the setup cells first.')\n",
        "    with open(config_path, 'r', encoding='utf-8') as fp:\n",
        "        workspace_config = json.load(fp)\n",
        "    PATHS = {k: Path(v) for k, v in workspace_config['paths'].items()}\n",
        "\n",
        "if 'search_agent' not in globals():\n",
        "    raise RuntimeError('Search agent not initialized. Run the agent cell first.')\n",
        "\n",
        "if 'ReportHelper' not in globals():\n",
        "    raise RuntimeError('ReportHelper not defined. Run the reporting helper cell first.')\n",
        "\n",
        "start_prompt_input = widgets.Textarea(\n",
        "    value=\"Compare the Samsung S25 Ultra versus the Google Pixel 10 Pro\",\n",
        "    description=\"Starting prompt:\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"80px\"),\n",
        ")\n",
        "\n",
        "persona_presets = [\n",
        "    (\"Budget college student (US)\", \"Budget-minded US college student upgrading an aging Android.\"),\n",
        "    (\"Enterprise IT director\", \"Enterprise IT director focused on security and lifecycle support.\"),\n",
        "    (\"Travel photographer\", \"Travel photographer who values camera quality and battery life.\"),\n",
        "    (\"Marathon runner\", \"Marathon runner looking for wearable integration and durability.\"),\n",
        "    (\"Custom persona\", \"custom\"),\n",
        "]\n",
        "\n",
        "persona_dropdown = widgets.Dropdown(options=persona_presets, value=persona_presets[0][1], description=\"Persona:\")\n",
        "persona_custom = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    description=\"Custom profile:\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"80px\"),\n",
        "    disabled=True,\n",
        ")\n",
        "\n",
        "turn_dropdown = widgets.Dropdown(options=[(\"1 turn\", 1), (\"3 turns\", 3), (\"5 turns\", 5)], value=5, description=\"Turns:\")\n",
        "context_dropdown = widgets.Dropdown(options=[(\"Low\", \"low\"), (\"Medium\", \"medium\"), (\"High\", \"high\")], value=\"medium\", description=\"Context:\")\n",
        "reasoning_dropdown = widgets.Dropdown(options=[(\"Low\", \"low\"), (\"Medium\", \"medium\"), (\"High\", \"high\")], value=\"low\", description=\"Reasoning:\")\n",
        "run_count_dropdown = widgets.Dropdown(\n",
        "    options=[(\"1 run\", 1), (\"3 runs\", 3), (\"5 runs\", 5), (\"10 runs\", 10), (\"20 runs\", 20)],\n",
        "    value=1,\n",
        "    description=\"# Runs:\",\n",
        ")\n",
        "\n",
        "location_toggle = widgets.Checkbox(value=False, description=\"Apply location bias\")\n",
        "location_presets = widgets.Dropdown(\n",
        "    options=[\n",
        "        (\"US ¬∑ New York\", \"us_ny\"),\n",
        "        (\"UK ¬∑ London\", \"uk_london\"),\n",
        "        (\"US ¬∑ San Francisco\", \"us_sf\"),\n",
        "        (\"France ¬∑ Paris\", \"fr_paris\"),\n",
        "        (\"Germany ¬∑ Berlin\", \"de_berlin\"),\n",
        "        (\"Custom\", \"custom\"),\n",
        "    ],\n",
        "    value=\"us_ny\",\n",
        "    description=\"Preset:\",\n",
        "    disabled=True,\n",
        ")\n",
        "custom_country = widgets.Text(value=\"US\", description=\"Country:\", disabled=True)\n",
        "custom_city = widgets.Text(value=\"New York\", description=\"City:\", disabled=True)\n",
        "custom_region = widgets.Text(value=\"New York\", description=\"Region:\", disabled=True)\n",
        "\n",
        "run_button = widgets.Button(description=\"Run Simulation\", button_style=\"primary\", icon=\"comments\")\n",
        "output = widgets.Output()\n",
        "\n",
        "preset_locations = {\n",
        "    \"us_ny\": (\"US\", \"New York\", \"New York\"),\n",
        "    \"uk_london\": (\"GB\", \"London\", \"London\"),\n",
        "    \"us_sf\": (\"US\", \"San Francisco\", \"California\"),\n",
        "    \"fr_paris\": (\"FR\", \"Paris\", \"√éle-de-France\"),\n",
        "    \"de_berlin\": (\"DE\", \"Berlin\", \"Berlin\"),\n",
        "}\n",
        "\n",
        "\n",
        "def update_persona(change=None):\n",
        "    persona_custom.disabled = persona_dropdown.value != \"custom\"\n",
        "\n",
        "\n",
        "def update_location(change=None):\n",
        "    enabled = location_toggle.value\n",
        "    location_presets.disabled = not enabled\n",
        "    is_custom = enabled and location_presets.value == \"custom\"\n",
        "    for widget in (custom_country, custom_city, custom_region):\n",
        "        widget.disabled = not is_custom\n",
        "\n",
        "\n",
        "persona_dropdown.observe(update_persona, \"value\")\n",
        "location_toggle.observe(update_location, \"value\")\n",
        "location_presets.observe(update_location, \"value\")\n",
        "update_persona()\n",
        "update_location()\n",
        "\n",
        "\n",
        "def get_persona_description():\n",
        "    if persona_dropdown.value == \"custom\":\n",
        "        return persona_custom.value.strip() or \"Curious consumer researching products.\"\n",
        "    return persona_dropdown.value\n",
        "\n",
        "\n",
        "def get_location_dict():\n",
        "    if not location_toggle.value:\n",
        "        return None\n",
        "    if location_presets.value != \"custom\":\n",
        "        country, city, region = preset_locations[location_presets.value]\n",
        "        return format_location(country=country, city=city, region=region)\n",
        "    country = custom_country.value or \"US\"\n",
        "    city = custom_city.value or \"New York\"\n",
        "    region = custom_region.value or city\n",
        "    return format_location(country=country, city=city, region=region)\n",
        "\n",
        "def simulate_persona_message(persona_profile: str, history: list, topic: str) -> str:\n",
        "    prompt = (\n",
        "        \"You are role-playing as the user described as: \"\n",
        "        + persona_profile\n",
        "        + \". You are conversing with an AI assistant about: \"\n",
        "        + topic\n",
        "        + \". Read the assistant's latest reply and respond naturally as this user would‚Äî\"\n",
        "          \"acknowledging what you just learned, sharing reactions or preferences, ALWAYS REMEMBER YOU ARE THE SHOPPER OR BUYER OR POTENTIAL CUSTOMER\"\n",
        "          \" or asking a follow-up question that moves the conversation forward. If the conversation is about a product, service, company or brand, seek to get relevant further information to inform your perception, understanding, knowledge or buying decision. Ask pertinent questions, that would enable you to make a good choice.\"\n",
        "          \" Stay in character and never interview the real user. Respond with a single message. Focus on learning more about the product or service or company as part of a buying research and consideration process. Keep your queries and follow ons relatively succinct - don't be verbose - or over-imagine - reflect the tone of someone conducting web research via an llm search assistant to get the info you need e.g. Instead of saying something like: It sounds like the battery life is decent, but I'm a bit concerned about how it will hold up during heavy use. Say something like: how long does the battery last for a heavy user? \"\n",
        "    )\n",
        "    response = search_agent.client.responses.create(\n",
        "        model=PERSONA_MODEL,\n",
        "        input=[{\"role\": \"system\", \"content\": prompt}] + history,\n",
        "    )\n",
        "    return search_agent.extract_text_response(response).strip()\n",
        "\n",
        "\n",
        "def run_simulation(_):\n",
        "    topic = start_prompt_input.value.strip()\n",
        "    turns = turn_dropdown.value\n",
        "    run_count = run_count_dropdown.value\n",
        "    persona_profile = get_persona_description()\n",
        "    user_location = get_location_dict()\n",
        "    model_name = getattr(search_agent, 'model', 'unknown')\n",
        "    persona_model_name = PERSONA_MODEL\n",
        "\n",
        "    with output:\n",
        "        clear_output()\n",
        "        if not topic:\n",
        "            print(\"‚ö†Ô∏è Please enter a starting prompt.\")\n",
        "            return\n",
        "\n",
        "        print(f\"‚ñ∂ Topic: {topic}\")\n",
        "        print(f\"‚ñ∂ Persona: {persona_profile}\")\n",
        "        print(f\"‚ñ∂ Turns per run: {turns}\")\n",
        "        print(f\"‚ñ∂ Runs: {run_count}\")\n",
        "        if user_location:\n",
        "            print(f\"üìç Location bias: {user_location}\\n\")\n",
        "        else:\n",
        "            print(\"üìç Location bias: none\\n\")\n",
        "\n",
        "        for run_idx in range(1, run_count + 1):\n",
        "            print(f\"\\n===== Run {run_idx}/{run_count} =====\")\n",
        "            reporter = ReportHelper('multi_turn', PATHS)\n",
        "            execution_id = reporter.execution_id\n",
        "            print(f\"‚ñ∂ Execution ID: {execution_id}\\n\")\n",
        "\n",
        "            persona_history = []\n",
        "            advisor_history = []\n",
        "\n",
        "            for turn in range(1, turns + 1):\n",
        "                turn_id = f\"{execution_id}_turn_{turn}\"\n",
        "                if turn == 1:\n",
        "                    persona_msg = topic\n",
        "                else:\n",
        "                    persona_msg = simulate_persona_message(persona_profile, persona_history + advisor_history, topic)\n",
        "                persona_history.append({\"role\": \"user\", \"content\": persona_msg})\n",
        "                print(f\"Turn {turn} ‚Äî Persona\")\n",
        "                print(persona_msg)\n",
        "                print()\n",
        "\n",
        "                reporter.add_detail_row(\n",
        "                    unit_id=turn_id,\n",
        "                    turn_or_run=turn,\n",
        "                    role='persona',\n",
        "                    model=persona_model_name,\n",
        "                    query_or_topic=topic,\n",
        "                    message_text=persona_msg,\n",
        "                    citation_rank=None,\n",
        "                    citation_title=None,\n",
        "                    citation_url=None,\n",
        "                    domain=None,\n",
        "                    context=context_dropdown.value,\n",
        "                    reasoning=reasoning_dropdown.value,\n",
        "                    location_country=user_location['country'] if user_location else None,\n",
        "                    location_city=user_location['city'] if user_location else None,\n",
        "                    location_region=user_location['region'] if user_location else None,\n",
        "                    response_file=None,\n",
        "                    persona_profile=persona_profile,\n",
        "                    persona_model=persona_model_name,\n",
        "                )\n",
        "\n",
        "                print(\"‚è≥ Advisor responding...\\n\")\n",
        "                response = search_agent.search(\n",
        "                    persona_msg,\n",
        "                    search_context_size=context_dropdown.value,\n",
        "                    reasoning_effort=reasoning_dropdown.value,\n",
        "                    verbosity=\"medium\",\n",
        "                    user_location=user_location,\n",
        "                )\n",
        "\n",
        "                raw_path = reporter.save_raw_response(f\"turn_{turn}\", response)\n",
        "                print_search_result(response)\n",
        "                print()\n",
        "\n",
        "                advisor_text = search_agent.extract_text_response(response)\n",
        "                advisor_history.append({\"role\": \"assistant\", \"content\": advisor_text})\n",
        "\n",
        "                citations = search_agent.extract_citations(response)\n",
        "                if citations:\n",
        "                    for rank, cite in enumerate(citations, 1):\n",
        "                        url = cite.get(\"url\", \"\")\n",
        "                        domain = urlparse(url).netloc.replace(\"www.\", \"\") if url else \"\"\n",
        "                        reporter.add_detail_row(\n",
        "                            unit_id=turn_id,\n",
        "                            turn_or_run=turn,\n",
        "                            role='AI System',\n",
        "                            model=model_name,\n",
        "                            query_or_topic=topic,\n",
        "                            message_text=advisor_text,\n",
        "                            citation_rank=rank,\n",
        "                            citation_title=cite.get(\"title\", \"\"),\n",
        "                            citation_url=url,\n",
        "                            domain=domain,\n",
        "                            context=context_dropdown.value,\n",
        "                            reasoning=reasoning_dropdown.value,\n",
        "                            location_country=user_location['country'] if user_location else None,\n",
        "                            location_city=user_location['city'] if user_location else None,\n",
        "                            location_region=user_location['region'] if user_location else None,\n",
        "                            response_file=str(raw_path),\n",
        "                            persona_profile=persona_profile,\n",
        "                            persona_model=persona_model_name,\n",
        "                        )\n",
        "                else:\n",
        "                    reporter.add_detail_row(\n",
        "                        unit_id=turn_id,\n",
        "                        turn_or_run=turn,\n",
        "                        role='AI System',\n",
        "                        model=model_name,\n",
        "                        query_or_topic=topic,\n",
        "                        message_text=advisor_text,\n",
        "                        citation_rank=None,\n",
        "                        citation_title=None,\n",
        "                        citation_url=None,\n",
        "                        domain=None,\n",
        "                        context=context_dropdown.value,\n",
        "                        reasoning=reasoning_dropdown.value,\n",
        "                        location_country=user_location['country'] if user_location else None,\n",
        "                        location_city=user_location['city'] if user_location else None,\n",
        "                        location_region=user_location['region'] if user_location else None,\n",
        "                        response_file=str(raw_path),\n",
        "                        persona_profile=persona_profile,\n",
        "                        persona_model=persona_model_name,\n",
        "                    )\n",
        "\n",
        "            detail_path = reporter.write_detail_csv()\n",
        "            df = pd.DataFrame(reporter._detail_rows)\n",
        "            advisor_citations = df[df['role'] == 'AI System'].dropna(subset=['citation_url'])\n",
        "            domain_counts = advisor_citations['domain'].value_counts().head(5)\n",
        "\n",
        "            print(\"=== Citation Summary ===\")\n",
        "            print(f\"Total AI System citations: {len(advisor_citations)}\")\n",
        "            print(f\"Unique citation URLs: {advisor_citations['citation_url'].nunique()}\")\n",
        "            if not domain_counts.empty:\n",
        "                print(\"Top cited domains:\")\n",
        "                for domain, count in domain_counts.items():\n",
        "                    print(f\"  ‚Ä¢ {domain}: {count}\")\n",
        "\n",
        "            summary_row = {\n",
        "                'model': model_name,\n",
        "                'topic': topic,\n",
        "                'turns': turns,\n",
        "                'persona_profile': persona_profile,\n",
        "                'persona_model': persona_model_name,\n",
        "                'location_country': user_location['country'] if user_location else None,\n",
        "                'location_city': user_location['city'] if user_location else None,\n",
        "                'location_region': user_location['region'] if user_location else None,\n",
        "                'total_citations': len(advisor_citations),\n",
        "                'unique_citation_urls': advisor_citations['citation_url'].nunique(),\n",
        "                'unique_domains': advisor_citations['domain'].nunique(),\n",
        "            }\n",
        "            for idx, (domain, count) in enumerate(domain_counts.items(), start=1):\n",
        "                summary_row[f\"top_domain_{idx}\"] = domain\n",
        "                summary_row[f\"top_domain_{idx}_count\"] = count\n",
        "\n",
        "            summary_path = reporter.write_summary_csv(summary_row)\n",
        "\n",
        "            print(f\"\\nüíæ Detail CSV: {detail_path}\")\n",
        "            print(f\"üíæ Summary CSV: {summary_path}\")\n",
        "            print(\"‚úÖ Run complete.\")\n",
        "\n",
        "\n",
        "run_button.on_click(run_simulation)\n",
        "\n",
        "controls = widgets.VBox([\n",
        "    start_prompt_input,\n",
        "    persona_dropdown,\n",
        "    persona_custom,\n",
        "    widgets.HBox([turn_dropdown, context_dropdown, reasoning_dropdown, run_count_dropdown]),\n",
        "    widgets.VBox([\n",
        "        location_toggle,\n",
        "        location_presets,\n",
        "        widgets.HBox([custom_country, custom_city, custom_region])\n",
        "    ]),\n",
        "    run_button,\n",
        "])\n",
        "\n",
        "display(widgets.VBox([controls, output]))\n"
      ],
      "id": "364Vki9iScGt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chDoRhtCScGt"
      },
      "source": [
        "# Analysis Step 1: Combine All Results for Reporting\n",
        "Now that you've run some searches, it's time to analyze the data. This cell gathers all of your saved search logs from the different run modes into a single \"master\" dataset. It also creates the interactive filters (like dropdowns and search bars) that you'll use in the reports below.\n"
      ],
      "id": "chDoRhtCScGt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkAWqy8wScGt"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Callable\n",
        "\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "\n",
        "AI_ROLE_LABEL = \"AI System\"\n",
        "LEGACY_ROLE_ALIASES = {\"advisor\"}\n",
        "\n",
        "\n",
        "def _load_paths():\n",
        "    if 'PATHS' in globals():\n",
        "        return {k: Path(v) for k, v in PATHS.items()}\n",
        "\n",
        "    config_path = os.environ.get(\"WORKSPACE_CONFIG\")\n",
        "    if not config_path or not Path(config_path).is_file():\n",
        "        raise RuntimeError(\"Workspace not configured. Run the workspace setup cell first.\")\n",
        "\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as fp:\n",
        "        data = json.load(fp)\n",
        "    return {k: Path(v) for k, v in data[\"paths\"].items()}\n",
        "\n",
        "\n",
        "PATH_MAP = _load_paths()\n",
        "CSV_DIR = PATH_MAP[\"csv_output\"]\n",
        "CACHE_DIR = CSV_DIR / \"report_cache\"\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "MASTER_PATH = CACHE_DIR / \"master_detail.csv\"\n",
        "MANIFEST_PATH = CACHE_DIR / \"manifest.json\"\n",
        "\n",
        "\n",
        "def _load_manifest() -> Dict[str, Any]:\n",
        "    if MANIFEST_PATH.is_file():\n",
        "        with MANIFEST_PATH.open(\"r\", encoding=\"utf-8\") as fp:\n",
        "            return json.load(fp)\n",
        "    return {\"processed_files\": {}}\n",
        "\n",
        "\n",
        "def _save_manifest(manifest: Dict[str, Any]) -> None:\n",
        "    with MANIFEST_PATH.open(\"w\", encoding=\"utf-8\") as fp:\n",
        "        json.dump(manifest, fp, indent=2)\n",
        "\n",
        "\n",
        "def _read_detail_file(path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    df[\"detail_file\"] = str(path)\n",
        "    return df\n",
        "\n",
        "\n",
        "def refresh_master_df(force_rebuild: bool = False) -> pd.DataFrame:\n",
        "    detail_files = sorted(CSV_DIR.glob(\"*_detail_*.csv\"))\n",
        "    manifest = _load_manifest()\n",
        "    processed = manifest.get(\"processed_files\", {})\n",
        "\n",
        "    if force_rebuild or not MASTER_PATH.is_file():\n",
        "        dfs = [_read_detail_file(f) for f in detail_files]\n",
        "        master_df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
        "        master_df.drop_duplicates(inplace=True)\n",
        "        master_df.to_csv(MASTER_PATH, index=False)\n",
        "        manifest[\"processed_files\"] = {\n",
        "            str(f): {\n",
        "                \"rows\": int(master_df[master_df[\"detail_file\"] == str(f)].shape[0]),\n",
        "                \"ingested_at\": datetime.utcnow().isoformat(),\n",
        "            }\n",
        "            for f in detail_files\n",
        "        }\n",
        "        _save_manifest(manifest)\n",
        "        return master_df\n",
        "\n",
        "    new_files = [f for f in detail_files if str(f) not in processed]\n",
        "    if not new_files:\n",
        "        return pd.read_csv(MASTER_PATH)\n",
        "\n",
        "    master_df = pd.read_csv(MASTER_PATH)\n",
        "    new_dfs = [_read_detail_file(f) for f in new_files]\n",
        "    new_df = pd.concat(new_dfs, ignore_index=True)\n",
        "    combined = pd.concat([master_df, new_df], ignore_index=True).drop_duplicates()\n",
        "    combined.to_csv(MASTER_PATH, index=False)\n",
        "\n",
        "    for f in new_files:\n",
        "        rows = int(new_df[new_df[\"detail_file\"] == str(f)].shape[0])\n",
        "        processed[str(f)] = {\"rows\": rows, \"ingested_at\": datetime.utcnow().isoformat()}\n",
        "\n",
        "    manifest[\"processed_files\"] = processed\n",
        "    _save_manifest(manifest)\n",
        "    return combined\n",
        "\n",
        "\n",
        "def refresh(force_rebuild: bool = False) -> pd.DataFrame:\n",
        "    \"\"\"Alias so older cells that call refresh() continue to work.\"\"\"\n",
        "    return refresh_master_df(force_rebuild=force_rebuild)\n",
        "\n",
        "\n",
        "def load_master_df() -> pd.DataFrame:\n",
        "    if MASTER_PATH.is_file():\n",
        "        return pd.read_csv(MASTER_PATH)\n",
        "    return refresh_master_df(force_rebuild=False)\n",
        "\n",
        "\n",
        "def dropdown_from_series(name: str, series: pd.Series, allow_blank: bool = False) -> widgets.Dropdown:\n",
        "    options = [\"All\"]\n",
        "    if allow_blank:\n",
        "        options.append(\"Blank\")\n",
        "    values = sorted({v for v in series.dropna().unique()} if not series.empty else [])\n",
        "    options.extend(values)\n",
        "    return widgets.Dropdown(description=name, options=options, value=\"All\")\n",
        "\n",
        "\n",
        "def create_filter_panel(df: pd.DataFrame, *, include_prompt_dropdown: bool = True, include_run_filters: bool = True) -> Dict[str, widgets.Widget]:\n",
        "    widgets_dict: Dict[str, widgets.Widget] = {\n",
        "        \"scenario\": dropdown_from_series(\"Scenario:\", df[\"scenario\"] if \"scenario\" in df else pd.Series(dtype=str)),\n",
        "        \"role\": dropdown_from_series(\"Role:\", df[\"role\"] if \"role\" in df else pd.Series(dtype=str)),\n",
        "        \"persona\": dropdown_from_series(\"Persona:\", df[\"persona_profile\"] if \"persona_profile\" in df else pd.Series(dtype=str), allow_blank=True),\n",
        "        \"model\": dropdown_from_series(\"Model:\", df[\"model\"] if \"model\" in df else pd.Series(dtype=str)),\n",
        "        \"execution\": dropdown_from_series(\"Execution ID:\", df[\"execution_id\"] if \"execution_id\" in df else pd.Series(dtype=str)),\n",
        "        \"country\": dropdown_from_series(\"Country:\", df[\"location_country\"] if \"location_country\" in df else pd.Series(dtype=str), allow_blank=True),\n",
        "        \"query_dropdown\": dropdown_from_series(\"Prompt:\", df[\"query_or_topic\"] if \"query_or_topic\" in df else pd.Series(dtype=str)),\n",
        "        \"query_text\": widgets.Text(description=\"Query search:\", placeholder=\"contains‚Ä¶\"),\n",
        "        \"message_text\": widgets.Text(description=\"Message search:\", placeholder=\"contains‚Ä¶\"),\n",
        "        \"citations_only\": widgets.Checkbox(description=\"Citations only\", value=False),\n",
        "        \"rows\": widgets.IntSlider(description=\"Rows\", value=25, min=5, max=200, step=5),\n",
        "    }\n",
        "\n",
        "    if include_run_filters:\n",
        "        widgets_dict[\"unit\"] = dropdown_from_series(\"Unit ID:\", df[\"unit_id\"] if \"unit_id\" in df else pd.Series(dtype=str))\n",
        "        widgets_dict[\"turn\"] = dropdown_from_series(\"Turn/Run #:\", df[\"turn_or_run\"] if \"turn_or_run\" in df else pd.Series(dtype=str))\n",
        "    else:\n",
        "        widgets_dict[\"unit\"] = widgets.Dropdown(description=\"Unit ID:\", options=[\"All\"], value=\"All\")\n",
        "        widgets_dict[\"turn\"] = widgets.Dropdown(description=\"Turn/Run #:\", options=[\"All\"], value=\"All\")\n",
        "\n",
        "    if not include_prompt_dropdown:\n",
        "        widgets_dict[\"query_dropdown\"].layout.display = \"none\"\n",
        "\n",
        "    return widgets_dict\n",
        "\n",
        "\n",
        "def apply_filters(df: pd.DataFrame, filters: Dict[str, widgets.Widget]) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    filtered = df.copy()\n",
        "\n",
        "    if \"scenario\" in filtered.columns and filters[\"scenario\"].value != \"All\":\n",
        "        filtered = filtered[filtered[\"scenario\"] == filters[\"scenario\"].value]\n",
        "    if \"role\" in filtered.columns and filters[\"role\"].value != \"All\":\n",
        "        filtered = filtered[filtered[\"role\"] == filters[\"role\"].value]\n",
        "    if \"model\" in filtered.columns and filters[\"model\"].value != \"All\":\n",
        "        filtered = filtered[filtered[\"model\"] == filters[\"model\"].value]\n",
        "    if \"execution_id\" in filtered.columns and filters[\"execution\"].value != \"All\":\n",
        "        filtered = filtered[filtered[\"execution_id\"] == filters[\"execution\"].value]\n",
        "\n",
        "    # Persona and country filters include blank option\n",
        "    if \"persona_profile\" in filtered.columns:\n",
        "        if filters[\"persona\"].value == \"Blank\":\n",
        "            filtered = filtered[filtered[\"persona_profile\"].isna()]\n",
        "        elif filters[\"persona\"].value != \"All\":\n",
        "            filtered = filtered[filtered[\"persona_profile\"] == filters[\"persona\"].value]\n",
        "\n",
        "    if \"location_country\" in filtered.columns:\n",
        "        if filters[\"country\"].value == \"Blank\":\n",
        "            filtered = filtered[filtered[\"location_country\"].isna()]\n",
        "        elif filters[\"country\"].value != \"All\":\n",
        "            filtered = filtered[filtered[\"location_country\"] == filters[\"country\"].value]\n",
        "\n",
        "    if filters[\"citations_only\"].value and \"citation_url\" in filtered.columns:\n",
        "        filtered = filtered[filtered[\"citation_url\"].notna()]\n",
        "\n",
        "    if \"unit_id\" in filtered.columns and filters[\"unit\"].value != \"All\":\n",
        "        filtered = filtered[filtered[\"unit_id\"] == filters[\"unit\"].value]\n",
        "    if \"turn_or_run\" in filtered.columns and filters[\"turn\"].value != \"All\":\n",
        "        value = filters[\"turn\"].value\n",
        "        filtered = filtered[filtered[\"turn_or_run\"].astype(str) == str(value)]\n",
        "\n",
        "    if \"query_or_topic\" in filtered.columns:\n",
        "        dropdown_value = filters[\"query_dropdown\"].value\n",
        "        if dropdown_value != \"All\":\n",
        "            filtered = filtered[filtered[\"query_or_topic\"] == dropdown_value]\n",
        "\n",
        "    query_text = filters[\"query_text\"].value.strip().lower()\n",
        "    if query_text and \"query_or_topic\" in filtered.columns:\n",
        "        filtered = filtered[\n",
        "            filtered[\"query_or_topic\"].str.lower().str.contains(query_text, na=False)\n",
        "        ]\n",
        "\n",
        "    message_text = filters[\"message_text\"].value.strip().lower()\n",
        "    if message_text:\n",
        "        filtered = filtered[\n",
        "            (filtered[\"message_text\"].str.lower().str.contains(message_text, na=False) if \"message_text\" in filtered.columns else False)\n",
        "            | (filtered[\"citation_title\"].str.lower().str.contains(message_text, na=False) if \"citation_title\" in filtered.columns else False)\n",
        "            | (filtered[\"citation_url\"].str.lower().str.contains(message_text, na=False) if \"citation_url\" in filtered.columns else False)\n",
        "        ]\n",
        "\n",
        "    return filtered\n",
        "\n",
        "\n",
        "def export_dataframe(df: pd.DataFrame, name: str) -> Path:\n",
        "    if df.empty:\n",
        "        raise ValueError(\"No data to export.\")\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    path = CSV_DIR / f\"{name}_{timestamp}.csv\"\n",
        "    df.to_csv(path, index=False)\n",
        "    return path\n",
        "\n",
        "\n",
        "def normalize_role_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Return a copy with legacy role names mapped to the canonical label.\"\"\"\n",
        "    if \"role\" not in df.columns or df.empty:\n",
        "        return df\n",
        "    normalized = df.copy()\n",
        "    rename_map = {alias: AI_ROLE_LABEL for alias in LEGACY_ROLE_ALIASES}\n",
        "    normalized[\"role\"] = normalized[\"role\"].replace(rename_map)\n",
        "    return normalized\n",
        "\n",
        "\n",
        "print(\"‚úÖ Master dataset helpers ready. Use refresh_master_df()/refresh(), create_filter_panel(), apply_filters(), and export_dataframe().\")\n"
      ],
      "id": "AkAWqy8wScGt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAs9JUE2ScGu"
      },
      "source": [
        "# Analysis Step 2: Create a Report on Cited Websites\n",
        "This report gives you a high-level view of your results by grouping citations by the main website (e.g., `theverge.com` or `wikipedia.org`). It's designed to help you answer the question: \"Which websites are appearing most often as authorities for my topics?\"\n",
        "\n",
        "### Using the Filters\n",
        "Before running the report, you can use the filter controls (like dropdown menus and search boxes) to narrow down your dataset. This allows you to focus on a specific scenario, persona, prompt, or time frame. The metrics in the report will update based on your filtered selection.\n",
        "\n",
        "### Report Metrics Guide\n",
        "Here‚Äôs a guide to what each column in the report means:\n",
        "\n",
        "- **Domain**: The main website address (e.g., `theverge.com`) that was cited.\n",
        "- **Appearances**: The total number of times this domain was cited in the filtered results.\n",
        "- **Unique Pages**: The number of different, specific articles from this domain that were cited.\n",
        "- **Prompts w/ Citations**: How many of your unique prompts led to this domain being cited.\n",
        "- **Prompt Reach %**: The percentage of *all* unique prompts in your filtered view that cited this domain. This shows how widely the domain is seen as an authority across different topics.\n",
        "- **Outputs w/ Citations**: The number of individual AI responses that included a citation from this domain.\n",
        "- **Output Hit Rate %**: The percentage of *all* AI responses that cited this domain. This shows how frequently it appears, especially when you re-run the same prompt.\n",
        "- **Avg Cites/Output**: The average number of citations a domain gets in a single AI response where it appears. A high number means it's often cited multiple times.\n",
        "- **Avg / Median / Std Position**: Statistics on the citation's rank in the list of sources (lower is better). The standard deviation (`std`) shows if the ranking is consistent or volatile.\n",
        "- **Top 3 Rate %**: The percentage of time this domain appeared in the top 3 citation spots.\n",
        "- **Consistency**: A score based on the ranking's standard deviation. A higher score means the domain's rank is more stable and predictable.\n",
        "- **First / Last Seen**: The timestamps for the first and most recent time the domain appeared in your data, which is useful for seeing if a source is still current.\n"
      ],
      "id": "MAs9JUE2ScGu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYTUSMWeScGu"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title Definitive Citation Intelligence Report (Domain view)\n",
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse\n",
        "import sys\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "try:\n",
        "    refresh_master_df\n",
        "    create_filter_panel\n",
        "    apply_filters\n",
        "    export_dataframe\n",
        "    normalize_role_labels\n",
        "except NameError as exc:  # pragma: no cover - notebook guard\n",
        "    raise RuntimeError(\"Run Cell 11a first to load master dataset helpers.\") from exc\n",
        "\n",
        "\n",
        "AI_ROLE = globals().get(\"AI_ROLE_LABEL\", \"AI System\")\n",
        "\n",
        "\n",
        "REPORT_COLUMNS = [\n",
        "\t\"Domain\",\n",
        "\t\"Unique Pages Cited\",\n",
        "\t\"Total Page Citations\",\n",
        "\t\"Domain Citation Share %\",\n",
        "\t\"Total Outputs Citing Page\",\n",
        "\t\"% of Total Outputs Citing Page\",\n",
        "\t\"Avg Citations per Output\",\n",
        "\t\"Total Prompt Runs Citing Page\",\n",
        "\t\"Unique Prompts Citing Page\",\n",
        "\t\"% of Unique Prompts Citing Page\",\n",
        "\t\"% of Total Prompt Runs Citing Page\",\n",
        "\t\"Prompt Repetition Rate\",\n",
        "\t\"Source Character\",\n",
        "\t\"Overall Average Rank\",\n",
        "\t\"Avg Rank on Repeated Prompts\",\n",
        "\t\"Avg Rank on Unique Prompts\",\n",
        "\t\"% of Citations in Top 3\",\n",
        "\t\"Rank Quality Score\",\n",
        "\t\"First Seen Timestamp\",\n",
        "\t\"Last Seen Timestamp\",\n",
        "\t\"Days Since Last Seen\",\n",
        "\t\"Recent Citation Velocity\",\n",
        "\t\"Predictability Score\",\n",
        "\t\"Topical Authority Score\",\n",
        "\t\"Overall Impact Score\",\n",
        "]\n",
        "\n",
        "DEFAULT_DISPLAY_COLUMNS = [\n",
        "    \"Domain\",\n",
        "    \"Unique Pages Cited\",\n",
        "    \"Total Page Citations\",\n",
        "    \"Total Outputs Citing Page\",\n",
        "    \"Avg Citations per Output\",\n",
        "    \"Total Prompt Runs Citing Page\",\n",
        "    \"Unique Prompts Citing Page\",\n",
        "    \"% of Unique Prompts Citing Page\",\n",
        "    \"% of Total Prompt Runs Citing Page\",\n",
        "    \"Avg Rank on Repeated Prompts\",\n",
        "    \"Avg Rank on Unique Prompts\",\n",
        "    \"% of Citations in Top 3\",\n",
        "    \"Rank Quality Score\",\n",
        "    \"Topical Authority Score\",\n",
        "    \"Overall Impact Score\",\n",
        "]\n",
        "\n",
        "\n",
        "SORT_OPTIONS = [(\"Domain (A-Z)\", \"Domain\")] + [(col, col) for col in REPORT_COLUMNS if col != \"Domain\"]\n",
        "\n",
        "LAST_REPORT = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "LAST_VIEW = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "\n",
        "\n",
        "def maybe_trigger_download(path: Path) -> None:\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        try:\n",
        "            from google.colab import files  # type: ignore\n",
        "\n",
        "            files.download(str(path))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "\n",
        "def clean_url(url: str) -> str:\n",
        "    if not isinstance(url, str):\n",
        "        return \"\"\n",
        "    sanitized = url.strip()\n",
        "    if not sanitized:\n",
        "        return \"\"\n",
        "    if \"?utm_\" in sanitized:\n",
        "        sanitized = sanitized.split(\"?utm_\")[0]\n",
        "    return sanitized\n",
        "\n",
        "\n",
        "def extract_domain(url: str) -> str:\n",
        "    parsed = urlparse(url)\n",
        "    netloc = parsed.netloc.replace(\"www.\", \"\")\n",
        "    return netloc or parsed.path or url\n",
        "\n",
        "\n",
        "def derive_run_id(row: pd.Series) -> str:\n",
        "    exec_id = row.get(\"execution_id\") or \"exec\"\n",
        "    turn = row.get(\"turn_or_run\")\n",
        "    if pd.isna(turn) or turn == \"\":\n",
        "        turn = row.get(\"unit_id\") or \"unit\"\n",
        "    return f\"{exec_id}|{turn}\"\n",
        "\n",
        "\n",
        "def derive_prompt_run_id(row: pd.Series) -> str:\n",
        "    unit = row.get(\"unit_id\")\n",
        "    if pd.notna(unit) and unit != \"\":\n",
        "        return str(unit)\n",
        "    return row.get(\"run_id\") or derive_run_id(row)\n",
        "\n",
        "\n",
        "def label_source_character(rate: float) -> str:\n",
        "    if rate >= 2.0:\n",
        "        return \"Niche Specialist\"\n",
        "    if rate >= 1.2:\n",
        "        return \"Focused Authority\"\n",
        "    return \"General Authority\"\n",
        "\n",
        "\n",
        "def compute_rank_quality_score(ranks: pd.Series) -> float:\n",
        "    if ranks.empty:\n",
        "        return 0.0\n",
        "    capped = ranks.clip(lower=1, upper=50)\n",
        "    points = capped.apply(lambda r: max(0, 11 - min(int(r), 10)))\n",
        "    return float(points.sum() / (10 * len(points)) * 100)\n",
        "\n",
        "\n",
        "def compute_topical_authority_score(unique_prompt_pct: float, avg_rank_unique: float | None) -> float:\n",
        "    if pd.isna(avg_rank_unique) or avg_rank_unique is None:\n",
        "        rank_component = 50.0\n",
        "    else:\n",
        "        rank_component = max(0.0, (10 - min(avg_rank_unique, 10)) / 9 * 100)\n",
        "    return (unique_prompt_pct + rank_component) / 2\n",
        "\n",
        "\n",
        "def format_timestamp_short(value: object) -> str:\n",
        "    if value in (None, \"\", \"NaT\"):\n",
        "        return \"\"\n",
        "    ts = pd.to_datetime(value, errors=\"coerce\", utc=True)\n",
        "    if pd.isna(ts):\n",
        "        return \"\"\n",
        "    return ts.tz_convert(\"UTC\").strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "\n",
        "def format_numeric(value: object, decimals: int = 2) -> str:\n",
        "    if pd.isna(value):\n",
        "        return \"\"\n",
        "    return f\"{float(value):.{decimals}f}\"\n",
        "\n",
        "\n",
        "def _build_domain_options(df: pd.DataFrame) -> list[str]:\n",
        "    if df.empty or \"citation_url\" not in df.columns:\n",
        "        return [\"All\"]\n",
        "    domains = {\n",
        "        extract_domain(clean_url(url))\n",
        "        for url in df[\"citation_url\"].dropna()\n",
        "        if isinstance(url, str) and clean_url(url)\n",
        "    }\n",
        "    return [\"All\"] + sorted(domains)\n",
        "\n",
        "\n",
        "POTENTIAL_OUTPUT_COLUMNS = [\n",
        "    \"message_text\",\n",
        "    \"assistant_response\",\n",
        "    \"model_response\",\n",
        "    \"response_text\",\n",
        "    \"citation_title\",\n",
        "    \"citation_text\",\n",
        "    \"query_or_topic\",\n",
        "]\n",
        "\n",
        "\n",
        "def build_citation_intelligence(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    advisor_rows = df[df[\"role\"] == AI_ROLE].copy()\n",
        "    citations = advisor_rows.dropna(subset=[\"citation_url\"]).copy()\n",
        "    if citations.empty:\n",
        "        return pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "\n",
        "    citations[\"run_id\"] = citations.apply(derive_run_id, axis=1)\n",
        "    citations[\"prompt_run_id\"] = citations.apply(derive_prompt_run_id, axis=1)\n",
        "    citations[\"clean_url\"] = citations[\"citation_url\"].apply(clean_url)\n",
        "    citations = citations[citations[\"clean_url\"] != \"\"]\n",
        "    if citations.empty:\n",
        "        return pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "\n",
        "    citations[\"domain\"] = citations[\"clean_url\"].apply(extract_domain)\n",
        "    citations = citations[citations[\"domain\"] != \"\"]\n",
        "    citations[\"citation_rank\"] = pd.to_numeric(citations[\"citation_rank\"], errors=\"coerce\")\n",
        "    citations[\"row_timestamp\"] = pd.to_datetime(citations[\"row_timestamp\"], errors=\"coerce\", utc=True)\n",
        "    citations[\"query_or_topic\"] = citations[\"query_or_topic\"].fillna(\"Unknown prompt\")\n",
        "\n",
        "    total_outputs = max(citations[\"run_id\"].nunique(), 1)\n",
        "    total_prompt_runs = max(citations[\"prompt_run_id\"].nunique(), 1)\n",
        "    total_unique_prompts = max(citations[\"query_or_topic\"].nunique(), 1)\n",
        "\n",
        "    prompt_run_counts = citations.groupby(\"query_or_topic\")[\"prompt_run_id\"].nunique().to_dict()\n",
        "    domain_totals = citations.groupby(\"domain\")[\"clean_url\"].count().to_dict()\n",
        "\n",
        "    now_ts = pd.Timestamp.utcnow()\n",
        "    if now_ts.tzinfo is None:\n",
        "        now_ts = now_ts.tz_localize(\"UTC\")\n",
        "    else:\n",
        "        now_ts = now_ts.tz_convert(\"UTC\")\n",
        "    window_start = now_ts - pd.Timedelta(days=7)\n",
        "\n",
        "    records: list[dict[str, object]] = []\n",
        "    for domain, group in citations.groupby(\"domain\"):\n",
        "        total_citations = int(group.shape[0])\n",
        "        domain_total = max(domain_totals.get(domain, total_citations), 1)\n",
        "        domain_share_pct = (total_citations / domain_total) * 100\n",
        "\n",
        "        outputs_with_domain = group[\"run_id\"].nunique()\n",
        "        outputs_pct = (outputs_with_domain / total_outputs) * 100\n",
        "\n",
        "        prompt_runs_with_domain = group[\"prompt_run_id\"].nunique()\n",
        "        prompt_runs_pct = (prompt_runs_with_domain / total_prompt_runs) * 100\n",
        "\n",
        "        unique_prompts = group[\"query_or_topic\"].nunique()\n",
        "        unique_prompts_pct = (unique_prompts / total_unique_prompts) * 100\n",
        "\n",
        "        prompt_repetition_rate = prompt_runs_with_domain / max(unique_prompts, 1)\n",
        "        source_character = label_source_character(prompt_repetition_rate)\n",
        "\n",
        "        ranks = group[\"citation_rank\"].dropna()\n",
        "        overall_avg_rank = ranks.mean() if not ranks.empty else None\n",
        "        top3_pct = float((ranks <= 3).mean() * 100) if not ranks.empty else 0.0\n",
        "\n",
        "        repeated_mask = group[\"query_or_topic\"].map(lambda q: prompt_run_counts.get(q, 0) > 1)\n",
        "        repeated_ranks = group.loc[repeated_mask, \"citation_rank\"].dropna()\n",
        "        avg_rank_repeated = repeated_ranks.mean() if not repeated_ranks.empty else None\n",
        "\n",
        "        unique_mask = group[\"query_or_topic\"].map(lambda q: prompt_run_counts.get(q, 0) <= 1)\n",
        "        unique_ranks = group.loc[unique_mask, \"citation_rank\"].dropna()\n",
        "        avg_rank_unique = unique_ranks.mean() if not unique_ranks.empty else None\n",
        "\n",
        "        rank_quality_score = compute_rank_quality_score(ranks)\n",
        "\n",
        "        timestamps = group[\"row_timestamp\"].dropna()\n",
        "        first_seen = timestamps.min()\n",
        "        last_seen = timestamps.max()\n",
        "        days_since_last_seen = (now_ts - last_seen).days if pd.notna(last_seen) else None\n",
        "        recent_count = int((timestamps >= window_start).sum())\n",
        "        recent_velocity = (recent_count / total_citations) * 100 if total_citations else 0.0\n",
        "\n",
        "        predictability_score = (outputs_pct + top3_pct) / 2\n",
        "        topical_authority_score = compute_topical_authority_score(unique_prompts_pct, avg_rank_unique)\n",
        "        overall_impact_score = (\n",
        "            (predictability_score * 0.4)\n",
        "            + (topical_authority_score * 0.3)\n",
        "            + (recent_velocity * 0.2)\n",
        "            + (domain_share_pct * 0.1)\n",
        "        )\n",
        "\n",
        "        records.append(\n",
        "            {\n",
        "                \"Domain\": domain,\n",
        "                \"Unique Pages Cited\": group[\"clean_url\"].nunique(),\n",
        "                \"Total Page Citations\": total_citations,\n",
        "                \"Domain Citation Share %\": domain_share_pct,\n",
        "                \"Total Outputs Citing Page\": outputs_with_domain,\n",
        "                \"% of Total Outputs Citing Page\": outputs_pct,\n",
        "                \"Avg Citations per Output\": total_citations / max(outputs_with_domain, 1),\n",
        "                \"Total Prompt Runs Citing Page\": prompt_runs_with_domain,\n",
        "                \"Unique Prompts Citing Page\": unique_prompts,\n",
        "                \"% of Unique Prompts Citing Page\": unique_prompts_pct,\n",
        "                \"% of Total Prompt Runs Citing Page\": prompt_runs_pct,\n",
        "                \"Prompt Repetition Rate\": prompt_repetition_rate,\n",
        "                \"Source Character\": source_character,\n",
        "                \"Overall Average Rank\": overall_avg_rank,\n",
        "                \"Avg Rank on Repeated Prompts\": avg_rank_repeated,\n",
        "                \"Avg Rank on Unique Prompts\": avg_rank_unique,\n",
        "                \"% of Citations in Top 3\": top3_pct,\n",
        "                \"Rank Quality Score\": rank_quality_score,\n",
        "                \"First Seen Timestamp\": first_seen.isoformat() if pd.notna(first_seen) else None,\n",
        "                \"Last Seen Timestamp\": last_seen.isoformat() if pd.notna(last_seen) else None,\n",
        "                \"Days Since Last Seen\": days_since_last_seen,\n",
        "                \"Recent Citation Velocity\": recent_velocity,\n",
        "                \"Predictability Score\": predictability_score,\n",
        "                \"Topical Authority Score\": topical_authority_score,\n",
        "                \"Overall Impact Score\": overall_impact_score,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return pd.DataFrame(records, columns=REPORT_COLUMNS)\n",
        "\n",
        "\n",
        "def format_domain_link(domain: str) -> str:\n",
        "    if not isinstance(domain, str):\n",
        "        return \"\"\n",
        "    return f'<a href=\"https://{domain}\" target=\"_blank\">{domain}</a>'\n",
        "\n",
        "\n",
        "master_df = normalize_role_labels(refresh_master_df(force_rebuild=False))\n",
        "filters = create_filter_panel(master_df)\n",
        "if \"role\" in filters and isinstance(filters[\"role\"], widgets.Widget):\n",
        "    role_options = getattr(filters[\"role\"], \"options\", [])\n",
        "    if isinstance(role_options, (list, tuple)) and AI_ROLE in role_options:\n",
        "        filters[\"role\"].value = AI_ROLE\n",
        "\n",
        "domain_dropdown = widgets.Dropdown(description=\"Domain:\", options=_build_domain_options(master_df), value=\"All\")\n",
        "domain_search = widgets.Text(description=\"Domain contains:\", placeholder=\"contains‚Ä¶\")\n",
        "page_search = widgets.Text(description=\"Page contains:\", placeholder=\"url or slug‚Ä¶\")\n",
        "output_text_filter = widgets.Text(description=\"Output text:\", placeholder=\"prompt/output contains‚Ä¶\")\n",
        "\n",
        "column_checkboxes = {\n",
        "    col: widgets.Checkbox(description=col, value=col in DEFAULT_DISPLAY_COLUMNS)\n",
        "    for col in REPORT_COLUMNS\n",
        "}\n",
        "column_picker_grid = widgets.GridBox(\n",
        "    list(column_checkboxes.values()),\n",
        "    layout=widgets.Layout(grid_template_columns=\"repeat(2, 50%)\", grid_gap=\"4px 12px\"),\n",
        ")\n",
        "column_picker_box = widgets.VBox([widgets.HTML(\"<b>Select columns to display:</b>\"), column_picker_grid])\n",
        "column_picker = widgets.Accordion(children=[column_picker_box])\n",
        "column_picker.set_title(0, \"+ Column picker\")\n",
        "column_picker.selected_index = None\n",
        "\n",
        "sort_column = widgets.Dropdown(description=\"Sort by:\", options=SORT_OPTIONS, value=\"Overall Impact Score\")\n",
        "sort_order = widgets.ToggleButtons(\n",
        "    description=\"Order:\",\n",
        "    options=[(\"Desc\", \"desc\"), (\"Asc\", \"asc\")],\n",
        "    value=\"desc\",\n",
        ")\n",
        "heading_html = widgets.HTML(\"<h3>Domain Citations Report</h3>\")\n",
        "refresh_button = widgets.Button(description=\"Refresh data\", icon=\"refresh\", button_style=\"primary\")\n",
        "rebuild_button = widgets.Button(description=\"Force rebuild\", icon=\"repeat\", button_style=\"danger\")\n",
        "export_table_button = widgets.Button(description=\"Export All\", icon=\"table\", button_style=\"warning\")\n",
        "export_view_button = widgets.Button(description=\"Export View\", icon=\"eye\", button_style=\"success\")\n",
        "export_highlights_button = widgets.Button(description=\"Export highlights\", icon=\"star\")\n",
        "export_highlights_button.style.button_color = \"#e0e0e0\"\n",
        "\n",
        "summary_output = widgets.Output()\n",
        "table_header = widgets.HTML(\"<h4>Domain performance metrics</h4>\")\n",
        "table_output = widgets.Output(layout=widgets.Layout(max_height=\"520px\", overflow=\"auto\"))\n",
        "message_output = widgets.Output()\n",
        "download_link_html = widgets.HTML()\n",
        "\n",
        "\n",
        "def sort_report(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "    ascending = sort_order.value == \"asc\"\n",
        "    return df.sort_values(sort_column.value, ascending=ascending)\n",
        "\n",
        "\n",
        "def compute_summary(df: pd.DataFrame) -> dict[str, int | float]:\n",
        "    advisor_rows = df[df[\"role\"] == AI_ROLE].copy()\n",
        "    if advisor_rows.empty:\n",
        "        return {\n",
        "            \"total_prompts\": 0,\n",
        "            \"prompt_with_cites\": 0,\n",
        "            \"total_outputs\": 0,\n",
        "            \"outputs_with_cites\": 0,\n",
        "            \"total_citations\": 0,\n",
        "        }\n",
        "\n",
        "    advisor_rows[\"run_id\"] = advisor_rows.apply(derive_run_id, axis=1)\n",
        "    advisor_rows[\"prompt_run_id\"] = advisor_rows.apply(derive_prompt_run_id, axis=1)\n",
        "    advisor_rows[\"query_or_topic\"] = advisor_rows[\"query_or_topic\"].fillna(\"Unknown prompt\")\n",
        "\n",
        "    total_prompts = advisor_rows[\"query_or_topic\"].nunique()\n",
        "    total_outputs = advisor_rows[\"run_id\"].nunique()\n",
        "\n",
        "    cited = advisor_rows.dropna(subset=[\"citation_url\"]).copy()\n",
        "    if cited.empty:\n",
        "        return {\n",
        "            \"total_prompts\": total_prompts,\n",
        "            \"prompt_with_cites\": 0,\n",
        "            \"total_outputs\": total_outputs,\n",
        "            \"outputs_with_cites\": 0,\n",
        "            \"total_citations\": 0,\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"total_prompts\": total_prompts,\n",
        "        \"prompt_with_cites\": cited[\"query_or_topic\"].nunique(),\n",
        "        \"total_outputs\": total_outputs,\n",
        "        \"outputs_with_cites\": cited[\"run_id\"].nunique(),\n",
        "        \"total_citations\": int(cited.shape[0]),\n",
        "    }\n",
        "\n",
        "\n",
        "def apply_custom_filters(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    working = df.copy()\n",
        "    if \"citation_url\" in working.columns:\n",
        "        working[\"__domain\"] = working[\"citation_url\"].apply(lambda url: extract_domain(clean_url(url)) if isinstance(url, str) else \"\")\n",
        "    else:\n",
        "        working[\"__domain\"] = \"\"\n",
        "\n",
        "    if domain_dropdown.value != \"All\":\n",
        "        working = working[working[\"__domain\"] == domain_dropdown.value]\n",
        "\n",
        "    domain_contains = domain_search.value.strip().lower()\n",
        "    if domain_contains:\n",
        "        working = working[working[\"__domain\"].str.contains(domain_contains, case=False, na=False)]\n",
        "\n",
        "    page_contains = page_search.value.strip().lower()\n",
        "    if page_contains and \"citation_url\" in working.columns:\n",
        "        working = working[working[\"citation_url\"].astype(str).str.lower().str.contains(page_contains, na=False)]\n",
        "\n",
        "    output_contains = output_text_filter.value.strip().lower()\n",
        "    if output_contains:\n",
        "        mask = pd.Series(False, index=working.index)\n",
        "        for col in POTENTIAL_OUTPUT_COLUMNS:\n",
        "            if col in working.columns:\n",
        "                mask = mask | working[col].astype(str).str.lower().str.contains(output_contains, na=False)\n",
        "        if \"citation_url\" in working.columns:\n",
        "            mask = mask | working[\"citation_url\"].astype(str).str.lower().str.contains(output_contains, na=False)\n",
        "        working = working[mask]\n",
        "\n",
        "    return working.drop(columns=[\"__domain\"], errors=\"ignore\")\n",
        "\n",
        "\n",
        "def refresh_domain_options_widget() -> None:\n",
        "    options = _build_domain_options(master_df)\n",
        "    current = domain_dropdown.value if domain_dropdown.value in options else \"All\"\n",
        "    domain_dropdown.options = options\n",
        "    domain_dropdown.value = current\n",
        "\n",
        "\n",
        "def update_display(_=None):\n",
        "    global LAST_REPORT, LAST_VIEW\n",
        "\n",
        "    filtered = apply_filters(master_df, filters)\n",
        "    filtered = apply_custom_filters(filtered)\n",
        "    report_df = build_citation_intelligence(filtered)\n",
        "    summary = compute_summary(filtered)\n",
        "\n",
        "    with summary_output:\n",
        "        summary_output.clear_output()\n",
        "        display(HTML(\"<h4>Summary metrics</h4>\"))\n",
        "        if filtered.empty:\n",
        "            display(HTML(\"<p>No rows match the selected filters.</p>\"))\n",
        "            display(HTML(\"<br>\"))\n",
        "        elif report_df.empty:\n",
        "            display(HTML(\"<p>No citations available for the current selection.</p>\"))\n",
        "            display(HTML(\"<br>\"))\n",
        "        else:\n",
        "            avg_cites_per_output = summary[\"total_citations\"] / max(summary[\"total_outputs\"], 1)\n",
        "            avg_cites_per_prompt = summary[\"total_citations\"] / max(summary[\"total_prompts\"], 1)\n",
        "            summary_df = pd.DataFrame(\n",
        "                [\n",
        "                    {\n",
        "                        \"Total Prompts\": f\"{summary['total_prompts']:,}\",\n",
        "                        \"Prompts w/ Citations\": f\"{summary['prompt_with_cites']:,}\",\n",
        "                        \"Total Outputs\": f\"{summary['total_outputs']:,}\",\n",
        "                        \"Outputs w/ Citations\": f\"{summary['outputs_with_cites']:,}\",\n",
        "                        \"Citations\": f\"{summary['total_citations']:,}\",\n",
        "                        \"Avg Cites/Output\": f\"{avg_cites_per_output:.2f}\",\n",
        "                        \"Avg Cites/Prompt\": f\"{avg_cites_per_prompt:.2f}\",\n",
        "                        \"Unique Domains\": f\"{report_df['Domain'].nunique():,}\",\n",
        "                        \"Unique Pages\": f\"{int(report_df['Unique Pages Cited'].sum()):,}\",\n",
        "                    }\n",
        "                ]\n",
        "            )\n",
        "            summary_html = summary_df.to_html(index=False, escape=False)\n",
        "            display(HTML(summary_html))\n",
        "            display(HTML(\"<br>\"))\n",
        "\n",
        "    with table_output:\n",
        "        table_output.clear_output()\n",
        "        if report_df.empty:\n",
        "            LAST_REPORT = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "            table_header.value = \"<h4>Domain performance metrics</h4>\"\n",
        "            return\n",
        "\n",
        "        sorted_df = sort_report(report_df)\n",
        "        LAST_REPORT = sorted_df\n",
        "        rows = filters[\"rows\"].value\n",
        "        display_df = sorted_df.head(rows).copy()\n",
        "        if display_df.empty:\n",
        "            print(\"No rows to display.\")\n",
        "            return\n",
        "\n",
        "        LAST_VIEW = display_df.copy()\n",
        "        display_df[\"Domain\"] = display_df[\"Domain\"].apply(format_domain_link)\n",
        "\n",
        "        percent_columns = [\n",
        "            \"Domain Citation Share %\",\n",
        "            \"% of Total Outputs Citing Page\",\n",
        "            \"% of Unique Prompts Citing Page\",\n",
        "            \"% of Total Prompt Runs Citing Page\",\n",
        "            \"% of Citations in Top 3\",\n",
        "            \"Rank Quality Score\",\n",
        "            \"Recent Citation Velocity\",\n",
        "            \"Predictability Score\",\n",
        "            \"Topical Authority Score\",\n",
        "        ]\n",
        "\n",
        "        for col in percent_columns:\n",
        "            if col in display_df.columns:\n",
        "                display_df[col] = display_df[col].map(lambda v: f\"{format_numeric(v, 2)}%\" if pd.notna(v) else \"\")\n",
        "\n",
        "        numeric_columns = [\n",
        "            \"Avg Citations per Output\",\n",
        "            \"Prompt Repetition Rate\",\n",
        "            \"Overall Impact Score\",\n",
        "            \"Overall Average Rank\",\n",
        "            \"Avg Rank on Repeated Prompts\",\n",
        "            \"Avg Rank on Unique Prompts\",\n",
        "        ]\n",
        "        for col in numeric_columns:\n",
        "            if col in display_df.columns:\n",
        "                display_df[col] = display_df[col].map(lambda v: format_numeric(v, 2))\n",
        "\n",
        "        selected_columns = [col for col, cb in column_checkboxes.items() if cb.value]\n",
        "        if not selected_columns:\n",
        "            selected_columns = DEFAULT_DISPLAY_COLUMNS\n",
        "\n",
        "        for ts_col in (\"First Seen Timestamp\", \"Last Seen Timestamp\"):\n",
        "            if ts_col in display_df.columns:\n",
        "                display_df[ts_col] = display_df[ts_col].map(format_timestamp_short)\n",
        "\n",
        "        table_header.value = \"<h4>Domain performance metrics</h4>\"\n",
        "        subset = [c for c in selected_columns if c in display_df.columns]\n",
        "        table_html = display_df[subset].to_html(escape=False, index=False, classes=\"domain-report-table\")\n",
        "        styled_html = \"\"\"\n",
        "        <style>\n",
        "        .domain-report-table thead th {\n",
        "            position: sticky;\n",
        "            top: 0;\n",
        "            background: #f6f6f6;\n",
        "            z-index: 1;\n",
        "        }\n",
        "        .domain-report-table tbody td {\n",
        "            vertical-align: top;\n",
        "        }\n",
        "        </style>\n",
        "        \"\"\" + table_html\n",
        "        display(HTML(styled_html))\n",
        "\n",
        "\n",
        "def handle_refresh(_):\n",
        "    global master_df\n",
        "    master_df = normalize_role_labels(refresh_master_df(force_rebuild=False))\n",
        "    refresh_domain_options_widget()\n",
        "    update_display()\n",
        "\n",
        "\n",
        "def handle_rebuild(_):\n",
        "    global master_df\n",
        "    master_df = normalize_role_labels(refresh_master_df(force_rebuild=True))\n",
        "    refresh_domain_options_widget()\n",
        "    update_display()\n",
        "\n",
        "\n",
        "def _render_download_link(path: Path) -> str:\n",
        "    return f'<a href=\"file://{path.resolve()}\" target=\"_blank\">{path.name}</a>'\n",
        "\n",
        "\n",
        "def handle_export_table(_):\n",
        "    if LAST_REPORT.empty:\n",
        "        with message_output:\n",
        "            message_output.clear_output()\n",
        "            print(\"‚ö†Ô∏è Nothing to export yet.\")\n",
        "        download_link_html.value = \"\"\n",
        "        return\n",
        "    path = export_dataframe(LAST_REPORT, \"definitive_citation_report\")\n",
        "    maybe_trigger_download(path)\n",
        "    with message_output:\n",
        "        message_output.clear_output()\n",
        "        print(\"üìÑ Exported full dataset.\")\n",
        "    download_link_html.value = _render_download_link(path)\n",
        "\n",
        "\n",
        "def handle_export_view(_):\n",
        "    if LAST_VIEW.empty:\n",
        "        with message_output:\n",
        "            message_output.clear_output()\n",
        "            print(\"‚ö†Ô∏è No filtered rows to export yet.\")\n",
        "        download_link_html.value = \"\"\n",
        "        return\n",
        "    path = export_dataframe(LAST_VIEW, \"domain_report_view\")\n",
        "    maybe_trigger_download(path)\n",
        "    with message_output:\n",
        "        message_output.clear_output()\n",
        "        print(\"üìÑ Exported current view.\")\n",
        "    download_link_html.value = _render_download_link(path)\n",
        "\n",
        "\n",
        "def handle_export_highlights(_):\n",
        "    if LAST_REPORT.empty:\n",
        "        with message_output:\n",
        "            message_output.clear_output()\n",
        "            print(\"‚ö†Ô∏è Nothing to export yet.\")\n",
        "        download_link_html.value = \"\"\n",
        "        return\n",
        "    df = LAST_REPORT\n",
        "    highlights = pd.concat(\n",
        "        [\n",
        "            df.nlargest(5, \"Overall Impact Score\").assign(Highlight=\"impact_top5\"),\n",
        "            df.nlargest(5, \"Recent Citation Velocity\").assign(Highlight=\"velocity_top5\"),\n",
        "            df.nlargest(5, \"Topical Authority Score\").assign(Highlight=\"authority_top5\"),\n",
        "        ],\n",
        "        ignore_index=True,\n",
        "    ).drop_duplicates(subset=[\"Domain\", \"Highlight\"])\n",
        "    path = export_dataframe(highlights, \"citation_highlights\")\n",
        "    maybe_trigger_download(path)\n",
        "    with message_output:\n",
        "        message_output.clear_output()\n",
        "        print(\"üìÑ Highlight tables exported.\")\n",
        "    download_link_html.value = _render_download_link(path)\n",
        "\n",
        "\n",
        "refresh_button.on_click(handle_refresh)\n",
        "rebuild_button.on_click(handle_rebuild)\n",
        "export_table_button.on_click(handle_export_table)\n",
        "export_view_button.on_click(handle_export_view)\n",
        "export_highlights_button.on_click(handle_export_highlights)\n",
        "\n",
        "for widget in list(filters.values()) + [sort_column, sort_order]:\n",
        "    widget.observe(update_display, names=\"value\")\n",
        "\n",
        "for checkbox in column_checkboxes.values():\n",
        "    checkbox.observe(update_display, names=\"value\")\n",
        "\n",
        "def _sync_column_picker_title(change):\n",
        "    if change[\"name\"] == \"selected_index\":\n",
        "        column_picker.set_title(0, \"+ Column picker\" if change[\"new\"] is None else \"‚àí Column picker\")\n",
        "\n",
        "column_picker.observe(_sync_column_picker_title, names=\"selected_index\")\n",
        "\n",
        "domain_dropdown.observe(update_display, names=\"value\")\n",
        "domain_search.observe(update_display, names=\"value\")\n",
        "page_search.observe(update_display, names=\"value\")\n",
        "output_text_filter.observe(update_display, names=\"value\")\n",
        "\n",
        "refresh_domain_options_widget()\n",
        "\n",
        "filters[\"query_text\"].description = \"Prompt search:\"\n",
        "filters[\"message_text\"].description = \"Message search:\"\n",
        "\n",
        "for control in (domain_dropdown, domain_search, page_search, output_text_filter, filters[\"query_text\"], filters[\"message_text\"]):\n",
        "    control.style = {\"description_width\": \"150px\"}\n",
        "    control.layout = widgets.Layout(width=\"300px\")\n",
        "\n",
        "controls = widgets.VBox(\n",
        "    [\n",
        "        widgets.HBox(\n",
        "            [refresh_button, rebuild_button, export_table_button, export_view_button, export_highlights_button],\n",
        "            layout=widgets.Layout(margin=\"0 0 10px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [filters[\"scenario\"], filters[\"role\"], filters[\"persona\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [filters[\"model\"], filters[\"execution\"], filters[\"country\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [filters[\"query_dropdown\"], filters[\"query_text\"], filters[\"message_text\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [domain_dropdown, domain_search, page_search],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [output_text_filter, filters[\"unit\"], filters[\"turn\"], filters[\"citations_only\"], filters[\"rows\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [sort_column, sort_order],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "    ],\n",
        "    layout=widgets.Layout(width=\"100%\"),\n",
        ")\n",
        "\n",
        "status_box = widgets.VBox([message_output, download_link_html], layout=widgets.Layout(width=\"100%\"))\n",
        "app_layout = widgets.VBox(\n",
        "    [heading_html, controls, column_picker, summary_output, table_header, table_output, status_box],\n",
        "    layout=widgets.Layout(width=\"100%\"),\n",
        ")\n",
        "\n",
        "display(app_layout)\n",
        "update_display()\n"
      ],
      "id": "RYTUSMWeScGu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooxpaW7iScGv"
      },
      "source": [
        "# Analysis Step 3: Create a Report on Cited Articles\n",
        "This report drills down to the next level of detail. Instead of just showing the website, it focuses on the specific article URLs that were cited. This helps you answer: \"Which exact pages are being used as sources?\"\n",
        "\n",
        "### Using the Filters\n",
        "Before running the report, you can use the filter controls (like dropdown menus and search boxes) to narrow down your dataset. You can look for a specific article, domain, or prompt to see how individual URLs are performing.\n",
        "\n",
        "### Report Metrics Guide\n",
        "Here‚Äôs a guide to what each column in the report means:\n",
        "\n",
        "- **Article URL**: The specific, full URL of the article that was cited.\n",
        "- **Article Title**: The title of the cited article.\n",
        "- **Domain**: The main website address (e.g., `theverge.com`) the article belongs to.\n",
        "- **Appearances**: The total number of times this specific article was cited in the filtered results.\n",
        "- **Prompts w/ Citations**: How many of your unique prompts led to this article being cited.\n",
        "- **Prompt Reach %**: The percentage of *all* unique prompts in your filtered view that cited this article.\n",
        "- **Outputs w/ Citations**: The number of individual AI responses that included a citation for this article.\n",
        "- **Output Hit Rate %**: The percentage of *all* AI responses that cited this article.\n",
        "- **Avg / Median / Std Position**: Statistics on the article's rank in the list of sources (lower is better). The standard deviation (`std`) shows if the ranking is consistent.\n",
        "- **Top 3 Rate %**: The percentage of time this article appeared in the top 3 citation spots.\n",
        "- **First / Last Seen**: The timestamps for the first and most recent time the article appeared in your data.\n"
      ],
      "id": "ooxpaW7iScGv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAH9iaISScGv"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title Page-Level Citations Report\n",
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from urllib.parse import unquote, urlparse\n",
        "import sys\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "try:\n",
        "    refresh_master_df\n",
        "    create_filter_panel\n",
        "    apply_filters\n",
        "    export_dataframe\n",
        "    normalize_role_labels\n",
        "except NameError as exc:  # pragma: no cover - notebook guard\n",
        "    raise RuntimeError(\"Run Cell 11a first to load master dataset helpers.\") from exc\n",
        "\n",
        "\n",
        "AI_ROLE = globals().get(\"AI_ROLE_LABEL\", \"AI System\")\n",
        "\n",
        "\n",
        "REPORT_COLUMNS = [\n",
        "    \"Domain\",\n",
        "    \"Page Title\",\n",
        "    \"Full URL\",\n",
        "    \"Total Page Citations\",\n",
        "    \"Domain Citation Share %\",\n",
        "    \"Total Outputs Citing Page\",\n",
        "    \"% of Total Outputs Citing Page\",\n",
        "    \"Avg Citations per Output\",\n",
        "    \"Total Prompt Runs Citing Page\",\n",
        "    \"Unique Prompts Citing Page\",\n",
        "    \"% of Unique Prompts Citing Page\",\n",
        "    \"% of Total Prompt Runs Citing Page\",\n",
        "    \"Prompt Repetition Rate\",\n",
        "    \"Source Character\",\n",
        "    \"Overall Average Rank\",\n",
        "    \"Avg Rank on Repeated Prompts\",\n",
        "    \"Avg Rank on Unique Prompts\",\n",
        "    \"% of Citations in Top 3\",\n",
        "    \"Rank Quality Score\",\n",
        "    \"First Seen Timestamp\",\n",
        "    \"Last Seen Timestamp\",\n",
        "    \"Days Since Last Seen\",\n",
        "    \"Recent Citation Velocity\",\n",
        "    \"Predictability Score\",\n",
        "    \"Topical Authority Score\",\n",
        "    \"Overall Impact Score\",\n",
        "]\n",
        "\n",
        "DEFAULT_DISPLAY_COLUMNS = [\n",
        "    \"Domain\",\n",
        "    \"Page Title\",\n",
        "    \"Full URL\",\n",
        "    \"Total Page Citations\",\n",
        "    \"Total Outputs Citing Page\",\n",
        "    \"Avg Citations per Output\",\n",
        "    \"Total Prompt Runs Citing Page\",\n",
        "    \"Unique Prompts Citing Page\",\n",
        "    \"% of Unique Prompts Citing Page\",\n",
        "    \"% of Total Prompt Runs Citing Page\",\n",
        "    \"Avg Rank on Repeated Prompts\",\n",
        "    \"Avg Rank on Unique Prompts\",\n",
        "    \"% of Citations in Top 3\",\n",
        "    \"Rank Quality Score\",\n",
        "    \"Topical Authority Score\",\n",
        "    \"Overall Impact Score\",\n",
        "]\n",
        "\n",
        "\n",
        "SORT_OPTIONS = [\n",
        "    (\"Domain (A-Z)\", \"Domain\"),\n",
        "    (\"Page Title (A-Z)\", \"Page Title\"),\n",
        "    *[(col, col) for col in REPORT_COLUMNS if col not in {\"Domain\", \"Page Title\", \"Full URL\"}],\n",
        "]\n",
        "\n",
        "LAST_REPORT = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "LAST_VIEW = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "\n",
        "\n",
        "def maybe_trigger_download(path: Path) -> None:\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        try:\n",
        "            from google.colab import files  # type: ignore\n",
        "\n",
        "            files.download(str(path))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "\n",
        "def clean_url(url: str) -> str:\n",
        "    if not isinstance(url, str):\n",
        "        return \"\"\n",
        "    sanitized = url.strip()\n",
        "    if not sanitized:\n",
        "        return \"\"\n",
        "    if \"?utm_\" in sanitized:\n",
        "        sanitized = sanitized.split(\"?utm_\")[0]\n",
        "    return sanitized\n",
        "\n",
        "\n",
        "def extract_domain(url: str) -> str:\n",
        "    parsed = urlparse(url)\n",
        "    netloc = parsed.netloc.replace(\"www.\", \"\")\n",
        "    return netloc or parsed.path or url\n",
        "\n",
        "\n",
        "def derive_title_from_url(url: str) -> str:\n",
        "    parsed = urlparse(url)\n",
        "    slug = unquote(Path(parsed.path).name or parsed.netloc or url)\n",
        "    normalized = slug.replace(\"-\", \" \").replace(\"_\", \" \").strip()\n",
        "    if not normalized:\n",
        "        return extract_domain(url)\n",
        "    return normalized.title()\n",
        "\n",
        "\n",
        "def derive_run_id(row: pd.Series) -> str:\n",
        "    exec_id = row.get(\"execution_id\") or \"exec\"\n",
        "    turn = row.get(\"turn_or_run\")\n",
        "    if pd.isna(turn) or turn == \"\":\n",
        "        turn = row.get(\"unit_id\") or \"unit\"\n",
        "    return f\"{exec_id}|{turn}\"\n",
        "\n",
        "\n",
        "def derive_prompt_run_id(row: pd.Series) -> str:\n",
        "    unit = row.get(\"unit_id\")\n",
        "    if pd.notna(unit) and unit != \"\":\n",
        "        return str(unit)\n",
        "    return row.get(\"run_id\") or derive_run_id(row)\n",
        "\n",
        "\n",
        "def label_source_character(rate: float) -> str:\n",
        "    if rate >= 2.0:\n",
        "        return \"Niche Specialist\"\n",
        "    if rate >= 1.2:\n",
        "        return \"Focused Authority\"\n",
        "    return \"General Authority\"\n",
        "\n",
        "\n",
        "def compute_rank_quality_score(ranks: pd.Series) -> float:\n",
        "    if ranks.empty:\n",
        "        return 0.0\n",
        "    capped = ranks.clip(lower=1, upper=50)\n",
        "    points = capped.apply(lambda r: max(0, 11 - min(int(r), 10)))\n",
        "    return float(points.sum() / (10 * len(points)) * 100)\n",
        "\n",
        "\n",
        "def compute_topical_authority_score(unique_prompt_pct: float, avg_rank_unique: float | None) -> float:\n",
        "    if pd.isna(avg_rank_unique) or avg_rank_unique is None:\n",
        "        rank_component = 50.0\n",
        "    else:\n",
        "        rank_component = max(0.0, (10 - min(avg_rank_unique, 10)) / 9 * 100)\n",
        "    return (unique_prompt_pct + rank_component) / 2\n",
        "\n",
        "\n",
        "def format_timestamp_short(value: object) -> str:\n",
        "    if value in (None, \"\", \"NaT\"):\n",
        "        return \"\"\n",
        "    ts = pd.to_datetime(value, errors=\"coerce\", utc=True)\n",
        "    if pd.isna(ts):\n",
        "        return \"\"\n",
        "    return ts.tz_convert(\"UTC\").strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "\n",
        "def format_numeric(value: object, decimals: int = 2) -> str:\n",
        "    if pd.isna(value):\n",
        "        return \"\"\n",
        "    return f\"{float(value):.{decimals}f}\"\n",
        "\n",
        "\n",
        "def _build_domain_options(df: pd.DataFrame) -> list[str]:\n",
        "    if df.empty or \"citation_url\" not in df.columns:\n",
        "        return [\"All\"]\n",
        "    domains = {\n",
        "        extract_domain(clean_url(url))\n",
        "        for url in df[\"citation_url\"].dropna()\n",
        "        if isinstance(url, str) and clean_url(url)\n",
        "    }\n",
        "    return [\"All\"] + sorted(domains)\n",
        "\n",
        "\n",
        "POTENTIAL_OUTPUT_COLUMNS = [\n",
        "    \"message_text\",\n",
        "    \"assistant_response\",\n",
        "    \"model_response\",\n",
        "    \"response_text\",\n",
        "    \"citation_title\",\n",
        "    \"citation_text\",\n",
        "    \"query_or_topic\",\n",
        "]\n",
        "\n",
        "\n",
        "def build_citation_intelligence(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    advisor_rows = df[df[\"role\"] == AI_ROLE].copy()\n",
        "    citations = advisor_rows.dropna(subset=[\"citation_url\"]).copy()\n",
        "    if citations.empty:\n",
        "        return pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "\n",
        "    citations[\"run_id\"] = citations.apply(derive_run_id, axis=1)\n",
        "    citations[\"prompt_run_id\"] = citations.apply(derive_prompt_run_id, axis=1)\n",
        "    citations[\"clean_url\"] = citations[\"citation_url\"].apply(clean_url)\n",
        "    citations = citations[citations[\"clean_url\"] != \"\"]\n",
        "    if citations.empty:\n",
        "        return pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "\n",
        "    citations[\"domain\"] = citations[\"clean_url\"].apply(extract_domain)\n",
        "    citations = citations[citations[\"domain\"] != \"\"]\n",
        "    citations[\"citation_rank\"] = pd.to_numeric(citations[\"citation_rank\"], errors=\"coerce\")\n",
        "    citations[\"row_timestamp\"] = pd.to_datetime(citations[\"row_timestamp\"], errors=\"coerce\", utc=True)\n",
        "    citations[\"query_or_topic\"] = citations[\"query_or_topic\"].fillna(\"Unknown prompt\")\n",
        "\n",
        "    total_outputs = max(citations[\"run_id\"].nunique(), 1)\n",
        "    total_prompt_runs = max(citations[\"prompt_run_id\"].nunique(), 1)\n",
        "    total_unique_prompts = max(citations[\"query_or_topic\"].nunique(), 1)\n",
        "\n",
        "    prompt_run_counts = citations.groupby(\"query_or_topic\")[\"prompt_run_id\"].nunique().to_dict()\n",
        "    domain_totals = citations.groupby(\"domain\")[\"clean_url\"].count().to_dict()\n",
        "\n",
        "    now_ts = pd.Timestamp.utcnow()\n",
        "    if now_ts.tzinfo is None:\n",
        "        now_ts = now_ts.tz_localize(\"UTC\")\n",
        "    else:\n",
        "        now_ts = now_ts.tz_convert(\"UTC\")\n",
        "    window_start = now_ts - pd.Timedelta(days=7)\n",
        "\n",
        "    records: list[dict[str, object]] = []\n",
        "    for url, group in citations.groupby(\"clean_url\"):\n",
        "        domain = group[\"domain\"].iloc[0]\n",
        "        if \"citation_title\" in group.columns and group[\"citation_title\"].notna().any():\n",
        "            page_title = group[\"citation_title\"].dropna().iloc[0]\n",
        "        else:\n",
        "            page_title = derive_title_from_url(url)\n",
        "        total_citations = int(group.shape[0])\n",
        "        domain_total = max(domain_totals.get(domain, total_citations), 1)\n",
        "        domain_share_pct = (total_citations / domain_total) * 100\n",
        "\n",
        "        outputs_with_domain = group[\"run_id\"].nunique()\n",
        "        outputs_pct = (outputs_with_domain / total_outputs) * 100\n",
        "\n",
        "        prompt_runs_with_domain = group[\"prompt_run_id\"].nunique()\n",
        "        prompt_runs_pct = (prompt_runs_with_domain / total_prompt_runs) * 100\n",
        "\n",
        "        unique_prompts = group[\"query_or_topic\"].nunique()\n",
        "        unique_prompts_pct = (unique_prompts / total_unique_prompts) * 100\n",
        "\n",
        "        prompt_repetition_rate = prompt_runs_with_domain / max(unique_prompts, 1)\n",
        "        source_character = label_source_character(prompt_repetition_rate)\n",
        "\n",
        "        ranks = group[\"citation_rank\"].dropna()\n",
        "        overall_avg_rank = ranks.mean() if not ranks.empty else None\n",
        "        top3_pct = float((ranks <= 3).mean() * 100) if not ranks.empty else 0.0\n",
        "\n",
        "        repeated_mask = group[\"query_or_topic\"].map(lambda q: prompt_run_counts.get(q, 0) > 1)\n",
        "        repeated_ranks = group.loc[repeated_mask, \"citation_rank\"].dropna()\n",
        "        avg_rank_repeated = repeated_ranks.mean() if not repeated_ranks.empty else None\n",
        "\n",
        "        unique_mask = group[\"query_or_topic\"].map(lambda q: prompt_run_counts.get(q, 0) <= 1)\n",
        "        unique_ranks = group.loc[unique_mask, \"citation_rank\"].dropna()\n",
        "        avg_rank_unique = unique_ranks.mean() if not unique_ranks.empty else None\n",
        "\n",
        "        rank_quality_score = compute_rank_quality_score(ranks)\n",
        "\n",
        "        timestamps = group[\"row_timestamp\"].dropna()\n",
        "        first_seen = timestamps.min()\n",
        "        last_seen = timestamps.max()\n",
        "        days_since_last_seen = (now_ts - last_seen).days if pd.notna(last_seen) else None\n",
        "        recent_count = int((timestamps >= window_start).sum())\n",
        "        recent_velocity = (recent_count / total_citations) * 100 if total_citations else 0.0\n",
        "\n",
        "        predictability_score = (outputs_pct + top3_pct) / 2\n",
        "        topical_authority_score = compute_topical_authority_score(unique_prompts_pct, avg_rank_unique)\n",
        "        overall_impact_score = (\n",
        "            (predictability_score * 0.4)\n",
        "            + (topical_authority_score * 0.3)\n",
        "            + (recent_velocity * 0.2)\n",
        "            + (domain_share_pct * 0.1)\n",
        "        )\n",
        "\n",
        "        records.append(\n",
        "            {\n",
        "                \"Domain\": domain,\n",
        "                \"Page Title\": page_title,\n",
        "                \"Full URL\": url,\n",
        "                \"Total Page Citations\": total_citations,\n",
        "                \"Domain Citation Share %\": domain_share_pct,\n",
        "                \"Total Outputs Citing Page\": outputs_with_domain,\n",
        "                \"% of Total Outputs Citing Page\": outputs_pct,\n",
        "                \"Avg Citations per Output\": total_citations / max(outputs_with_domain, 1),\n",
        "                \"Total Prompt Runs Citing Page\": prompt_runs_with_domain,\n",
        "                \"Unique Prompts Citing Page\": unique_prompts,\n",
        "                \"% of Unique Prompts Citing Page\": unique_prompts_pct,\n",
        "                \"% of Total Prompt Runs Citing Page\": prompt_runs_pct,\n",
        "                \"Prompt Repetition Rate\": prompt_repetition_rate,\n",
        "                \"Source Character\": source_character,\n",
        "                \"Overall Average Rank\": overall_avg_rank,\n",
        "                \"Avg Rank on Repeated Prompts\": avg_rank_repeated,\n",
        "                \"Avg Rank on Unique Prompts\": avg_rank_unique,\n",
        "                \"% of Citations in Top 3\": top3_pct,\n",
        "                \"Rank Quality Score\": rank_quality_score,\n",
        "                \"First Seen Timestamp\": first_seen.isoformat() if pd.notna(first_seen) else None,\n",
        "                \"Last Seen Timestamp\": last_seen.isoformat() if pd.notna(last_seen) else None,\n",
        "                \"Days Since Last Seen\": days_since_last_seen,\n",
        "                \"Recent Citation Velocity\": recent_velocity,\n",
        "                \"Predictability Score\": predictability_score,\n",
        "                \"Topical Authority Score\": topical_authority_score,\n",
        "                \"Overall Impact Score\": overall_impact_score,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return pd.DataFrame(records, columns=REPORT_COLUMNS)\n",
        "\n",
        "\n",
        "def format_domain_link(domain: str) -> str:\n",
        "    if not isinstance(domain, str):\n",
        "        return \"\"\n",
        "    return f'<a href=\"https://{domain}\" target=\"_blank\">{domain}</a>'\n",
        "\n",
        "\n",
        "def format_url_link(url: str) -> str:\n",
        "    if not isinstance(url, str):\n",
        "        return \"\"\n",
        "    return f'<a href=\"{url}\" target=\"_blank\">Open</a>'\n",
        "\n",
        "\n",
        "master_df = normalize_role_labels(refresh_master_df(force_rebuild=False))\n",
        "filters = create_filter_panel(master_df)\n",
        "if \"role\" in filters and isinstance(filters[\"role\"], widgets.Widget):\n",
        "    role_options = getattr(filters[\"role\"], \"options\", [])\n",
        "    if isinstance(role_options, (list, tuple)) and AI_ROLE in role_options:\n",
        "        filters[\"role\"].value = AI_ROLE\n",
        "\n",
        "domain_dropdown = widgets.Dropdown(description=\"Domain:\", options=_build_domain_options(master_df), value=\"All\")\n",
        "domain_search = widgets.Text(description=\"Domain contains:\", placeholder=\"contains‚Ä¶\")\n",
        "page_search = widgets.Text(description=\"Page contains:\", placeholder=\"url or slug‚Ä¶\")\n",
        "output_text_filter = widgets.Text(description=\"Output text:\", placeholder=\"prompt/output contains‚Ä¶\")\n",
        "\n",
        "column_checkboxes = {\n",
        "    col: widgets.Checkbox(description=col, value=col in DEFAULT_DISPLAY_COLUMNS)\n",
        "    for col in REPORT_COLUMNS\n",
        "}\n",
        "column_picker_grid = widgets.GridBox(\n",
        "    list(column_checkboxes.values()),\n",
        "    layout=widgets.Layout(grid_template_columns=\"repeat(2, 50%)\", grid_gap=\"4px 12px\"),\n",
        ")\n",
        "column_picker_box = widgets.VBox([widgets.HTML(\"<b>Select columns to display:</b>\"), column_picker_grid])\n",
        "column_picker = widgets.Accordion(children=[column_picker_box])\n",
        "column_picker.set_title(0, \"+ Column picker\")\n",
        "column_picker.selected_index = None\n",
        "\n",
        "sort_column = widgets.Dropdown(description=\"Sort by:\", options=SORT_OPTIONS, value=\"Overall Impact Score\")\n",
        "sort_order = widgets.ToggleButtons(\n",
        "    description=\"Order:\",\n",
        "    options=[(\"Desc\", \"desc\"), (\"Asc\", \"asc\")],\n",
        "    value=\"desc\",\n",
        ")\n",
        "heading_html = widgets.HTML(\"<h3>Page-Level Citations Report</h3>\")\n",
        "refresh_button = widgets.Button(description=\"Refresh data\", icon=\"refresh\", button_style=\"primary\")\n",
        "rebuild_button = widgets.Button(description=\"Force rebuild\", icon=\"repeat\", button_style=\"danger\")\n",
        "export_table_button = widgets.Button(description=\"Export All\", icon=\"table\", button_style=\"warning\")\n",
        "export_view_button = widgets.Button(description=\"Export View\", icon=\"eye\", button_style=\"success\")\n",
        "export_highlights_button = widgets.Button(description=\"Export highlights\", icon=\"star\")\n",
        "export_highlights_button.style.button_color = \"#e0e0e0\"\n",
        "\n",
        "summary_output = widgets.Output()\n",
        "table_header = widgets.HTML(\"<h4>Page performance metrics</h4>\")\n",
        "table_output = widgets.Output(layout=widgets.Layout(max_height=\"520px\", overflow=\"auto\"))\n",
        "message_output = widgets.Output()\n",
        "download_link_html = widgets.HTML()\n",
        "\n",
        "\n",
        "def sort_report(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "    ascending = sort_order.value == \"asc\"\n",
        "    return df.sort_values(sort_column.value, ascending=ascending)\n",
        "\n",
        "\n",
        "def compute_summary(df: pd.DataFrame) -> dict[str, int | float]:\n",
        "    advisor_rows = df[df[\"role\"] == AI_ROLE].copy()\n",
        "    if advisor_rows.empty:\n",
        "        return {\n",
        "            \"total_prompts\": 0,\n",
        "            \"prompt_with_cites\": 0,\n",
        "            \"total_outputs\": 0,\n",
        "            \"outputs_with_cites\": 0,\n",
        "            \"total_citations\": 0,\n",
        "        }\n",
        "\n",
        "    advisor_rows[\"run_id\"] = advisor_rows.apply(derive_run_id, axis=1)\n",
        "    advisor_rows[\"prompt_run_id\"] = advisor_rows.apply(derive_prompt_run_id, axis=1)\n",
        "    advisor_rows[\"query_or_topic\"] = advisor_rows[\"query_or_topic\"].fillna(\"Unknown prompt\")\n",
        "\n",
        "    total_prompts = advisor_rows[\"query_or_topic\"].nunique()\n",
        "    total_outputs = advisor_rows[\"run_id\"].nunique()\n",
        "\n",
        "    cited = advisor_rows.dropna(subset=[\"citation_url\"]).copy()\n",
        "    if cited.empty:\n",
        "        return {\n",
        "            \"total_prompts\": total_prompts,\n",
        "            \"prompt_with_cites\": 0,\n",
        "            \"total_outputs\": total_outputs,\n",
        "            \"outputs_with_cites\": 0,\n",
        "            \"total_citations\": 0,\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"total_prompts\": total_prompts,\n",
        "        \"prompt_with_cites\": cited[\"query_or_topic\"].nunique(),\n",
        "        \"total_outputs\": total_outputs,\n",
        "        \"outputs_with_cites\": cited[\"run_id\"].nunique(),\n",
        "        \"total_citations\": int(cited.shape[0]),\n",
        "    }\n",
        "\n",
        "\n",
        "def apply_custom_filters(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    working = df.copy()\n",
        "    if \"citation_url\" in working.columns:\n",
        "        working[\"__domain\"] = working[\"citation_url\"].apply(lambda url: extract_domain(clean_url(url)) if isinstance(url, str) else \"\")\n",
        "    else:\n",
        "        working[\"__domain\"] = \"\"\n",
        "\n",
        "    if domain_dropdown.value != \"All\":\n",
        "        working = working[working[\"__domain\"] == domain_dropdown.value]\n",
        "\n",
        "    domain_contains = domain_search.value.strip().lower()\n",
        "    if domain_contains:\n",
        "        working = working[working[\"__domain\"].str.contains(domain_contains, case=False, na=False)]\n",
        "\n",
        "    page_contains = page_search.value.strip().lower()\n",
        "    if page_contains and \"citation_url\" in working.columns:\n",
        "        working = working[working[\"citation_url\"].astype(str).str.lower().str.contains(page_contains, na=False)]\n",
        "\n",
        "    output_contains = output_text_filter.value.strip().lower()\n",
        "    if output_contains:\n",
        "        mask = pd.Series(False, index=working.index)\n",
        "        for col in POTENTIAL_OUTPUT_COLUMNS:\n",
        "            if col in working.columns:\n",
        "                mask = mask | working[col].astype(str).str.lower().str.contains(output_contains, na=False)\n",
        "        if \"citation_url\" in working.columns:\n",
        "            mask = mask | working[\"citation_url\"].astype(str).str.lower().str.contains(output_contains, na=False)\n",
        "        working = working[mask]\n",
        "\n",
        "    return working.drop(columns=[\"__domain\"], errors=\"ignore\")\n",
        "\n",
        "\n",
        "def refresh_domain_options_widget() -> None:\n",
        "    options = _build_domain_options(master_df)\n",
        "    current = domain_dropdown.value if domain_dropdown.value in options else \"All\"\n",
        "    domain_dropdown.options = options\n",
        "    domain_dropdown.value = current\n",
        "\n",
        "\n",
        "def update_display(_=None):\n",
        "    global LAST_REPORT, LAST_VIEW\n",
        "\n",
        "    filtered = apply_filters(master_df, filters)\n",
        "    filtered = apply_custom_filters(filtered)\n",
        "    report_df = build_citation_intelligence(filtered)\n",
        "    summary = compute_summary(filtered)\n",
        "\n",
        "    with summary_output:\n",
        "        summary_output.clear_output()\n",
        "        display(HTML(\"<h4>Summary metrics</h4>\"))\n",
        "        if filtered.empty:\n",
        "            display(HTML(\"<p>No rows match the selected filters.</p>\"))\n",
        "            display(HTML(\"<br>\"))\n",
        "        elif report_df.empty:\n",
        "            display(HTML(\"<p>No citations available for the current selection.</p>\"))\n",
        "            display(HTML(\"<br>\"))\n",
        "        else:\n",
        "            avg_cites_per_output = summary[\"total_citations\"] / max(summary[\"total_outputs\"], 1)\n",
        "            avg_cites_per_prompt = summary[\"total_citations\"] / max(summary[\"total_prompts\"], 1)\n",
        "            summary_df = pd.DataFrame(\n",
        "                [\n",
        "                    {\n",
        "                        \"Total Prompts\": f\"{summary['total_prompts']:,}\",\n",
        "                        \"Prompts w/ Citations\": f\"{summary['prompt_with_cites']:,}\",\n",
        "                        \"Total Outputs\": f\"{summary['total_outputs']:,}\",\n",
        "                        \"Outputs w/ Citations\": f\"{summary['outputs_with_cites']:,}\",\n",
        "                        \"Citations\": f\"{summary['total_citations']:,}\",\n",
        "                        \"Avg Cites/Output\": f\"{avg_cites_per_output:.2f}\",\n",
        "                        \"Avg Cites/Prompt\": f\"{avg_cites_per_prompt:.2f}\",\n",
        "                        \"Unique Pages\": f\"{report_df.shape[0]:,}\",\n",
        "                        \"Unique Domains\": f\"{report_df['Domain'].nunique():,}\",\n",
        "                    }\n",
        "                ]\n",
        "            )\n",
        "            summary_html = summary_df.to_html(index=False, escape=False)\n",
        "            display(HTML(summary_html))\n",
        "            display(HTML(\"<br>\"))\n",
        "\n",
        "    with table_output:\n",
        "        table_output.clear_output()\n",
        "        if report_df.empty:\n",
        "            LAST_REPORT = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "            table_header.value = \"<h4>Domain performance metrics</h4>\"\n",
        "            return\n",
        "\n",
        "        sorted_df = sort_report(report_df)\n",
        "        LAST_REPORT = sorted_df\n",
        "        rows = filters[\"rows\"].value\n",
        "        display_df = sorted_df.head(rows).copy()\n",
        "        if display_df.empty:\n",
        "            print(\"No rows to display.\")\n",
        "            return\n",
        "\n",
        "        LAST_VIEW = display_df.copy()\n",
        "        display_df[\"Domain\"] = display_df[\"Domain\"].apply(format_domain_link)\n",
        "        if \"Full URL\" in display_df.columns:\n",
        "            display_df[\"Full URL\"] = display_df[\"Full URL\"].apply(format_url_link)\n",
        "\n",
        "        percent_columns = [\n",
        "            \"Domain Citation Share %\",\n",
        "            \"% of Total Outputs Citing Page\",\n",
        "            \"% of Unique Prompts Citing Page\",\n",
        "            \"% of Total Prompt Runs Citing Page\",\n",
        "            \"% of Citations in Top 3\",\n",
        "            \"Rank Quality Score\",\n",
        "            \"Recent Citation Velocity\",\n",
        "            \"Predictability Score\",\n",
        "            \"Topical Authority Score\",\n",
        "        ]\n",
        "\n",
        "        for col in percent_columns:\n",
        "            if col in display_df.columns:\n",
        "                display_df[col] = display_df[col].map(lambda v: f\"{format_numeric(v, 2)}%\" if pd.notna(v) else \"\")\n",
        "\n",
        "        numeric_columns = [\n",
        "            \"Avg Citations per Output\",\n",
        "            \"Prompt Repetition Rate\",\n",
        "            \"Overall Impact Score\",\n",
        "            \"Overall Average Rank\",\n",
        "            \"Avg Rank on Repeated Prompts\",\n",
        "            \"Avg Rank on Unique Prompts\",\n",
        "        ]\n",
        "        for col in numeric_columns:\n",
        "            if col in display_df.columns:\n",
        "                display_df[col] = display_df[col].map(lambda v: format_numeric(v, 2))\n",
        "\n",
        "        selected_columns = [col for col, cb in column_checkboxes.items() if cb.value]\n",
        "        if not selected_columns:\n",
        "            selected_columns = DEFAULT_DISPLAY_COLUMNS\n",
        "\n",
        "        for ts_col in (\"First Seen Timestamp\", \"Last Seen Timestamp\"):\n",
        "            if ts_col in display_df.columns:\n",
        "                display_df[ts_col] = display_df[ts_col].map(format_timestamp_short)\n",
        "\n",
        "        table_header.value = \"<h4>Page performance metrics</h4>\"\n",
        "        subset = [c for c in selected_columns if c in display_df.columns]\n",
        "        table_html = display_df[subset].to_html(escape=False, index=False, classes=\"domain-report-table\")\n",
        "        styled_html = \"\"\"\n",
        "        <style>\n",
        "        .domain-report-table thead th {\n",
        "            position: sticky;\n",
        "            top: 0;\n",
        "            background: #f6f6f6;\n",
        "            z-index: 1;\n",
        "        }\n",
        "        .domain-report-table tbody td {\n",
        "            vertical-align: top;\n",
        "        }\n",
        "        </style>\n",
        "        \"\"\" + table_html\n",
        "        display(HTML(styled_html))\n",
        "\n",
        "\n",
        "def handle_refresh(_):\n",
        "    global master_df\n",
        "    master_df = normalize_role_labels(refresh_master_df(force_rebuild=False))\n",
        "    refresh_domain_options_widget()\n",
        "    update_display()\n",
        "\n",
        "\n",
        "def handle_rebuild(_):\n",
        "    global master_df\n",
        "    master_df = normalize_role_labels(refresh_master_df(force_rebuild=True))\n",
        "    refresh_domain_options_widget()\n",
        "    update_display()\n",
        "\n",
        "\n",
        "def _render_download_link(path: Path) -> str:\n",
        "    return f'<a href=\"file://{path.resolve()}\" target=\"_blank\">{path.name}</a>'\n",
        "\n",
        "\n",
        "def handle_export_table(_):\n",
        "    if LAST_REPORT.empty:\n",
        "        with message_output:\n",
        "            message_output.clear_output()\n",
        "            print(\"‚ö†Ô∏è Nothing to export yet.\")\n",
        "        download_link_html.value = \"\"\n",
        "        return\n",
        "    path = export_dataframe(LAST_REPORT, \"definitive_citation_report\")\n",
        "    maybe_trigger_download(path)\n",
        "    with message_output:\n",
        "        message_output.clear_output()\n",
        "        print(\"üìÑ Exported full dataset.\")\n",
        "    download_link_html.value = _render_download_link(path)\n",
        "\n",
        "\n",
        "def handle_export_view(_):\n",
        "    if LAST_VIEW.empty:\n",
        "        with message_output:\n",
        "            message_output.clear_output()\n",
        "            print(\"‚ö†Ô∏è No filtered rows to export yet.\")\n",
        "        download_link_html.value = \"\"\n",
        "        return\n",
        "    path = export_dataframe(LAST_VIEW, \"domain_report_view\")\n",
        "    maybe_trigger_download(path)\n",
        "    with message_output:\n",
        "        message_output.clear_output()\n",
        "        print(\"üìÑ Exported current view.\")\n",
        "    download_link_html.value = _render_download_link(path)\n",
        "\n",
        "\n",
        "def handle_export_highlights(_):\n",
        "    if LAST_REPORT.empty:\n",
        "        with message_output:\n",
        "            message_output.clear_output()\n",
        "            print(\"‚ö†Ô∏è Nothing to export yet.\")\n",
        "        download_link_html.value = \"\"\n",
        "        return\n",
        "    df = LAST_REPORT\n",
        "    highlights = pd.concat(\n",
        "        [\n",
        "            df.nlargest(5, \"Overall Impact Score\").assign(Highlight=\"impact_top5\"),\n",
        "            df.nlargest(5, \"Recent Citation Velocity\").assign(Highlight=\"velocity_top5\"),\n",
        "            df.nlargest(5, \"Topical Authority Score\").assign(Highlight=\"authority_top5\"),\n",
        "        ],\n",
        "        ignore_index=True,\n",
        "    ).drop_duplicates(subset=[\"Full URL\", \"Highlight\"])\n",
        "    path = export_dataframe(highlights, \"citation_highlights\")\n",
        "    maybe_trigger_download(path)\n",
        "    with message_output:\n",
        "        message_output.clear_output()\n",
        "        print(\"üìÑ Highlight tables exported.\")\n",
        "    download_link_html.value = _render_download_link(path)\n",
        "\n",
        "\n",
        "refresh_button.on_click(handle_refresh)\n",
        "rebuild_button.on_click(handle_rebuild)\n",
        "export_table_button.on_click(handle_export_table)\n",
        "export_view_button.on_click(handle_export_view)\n",
        "export_highlights_button.on_click(handle_export_highlights)\n",
        "\n",
        "for widget in list(filters.values()) + [sort_column, sort_order]:\n",
        "    widget.observe(update_display, names=\"value\")\n",
        "\n",
        "for checkbox in column_checkboxes.values():\n",
        "    checkbox.observe(update_display, names=\"value\")\n",
        "\n",
        "def _sync_column_picker_title(change):\n",
        "    if change[\"name\"] == \"selected_index\":\n",
        "        column_picker.set_title(0, \"+ Column picker\" if change[\"new\"] is None else \"‚àí Column picker\")\n",
        "\n",
        "column_picker.observe(_sync_column_picker_title, names=\"selected_index\")\n",
        "\n",
        "domain_dropdown.observe(update_display, names=\"value\")\n",
        "domain_search.observe(update_display, names=\"value\")\n",
        "page_search.observe(update_display, names=\"value\")\n",
        "output_text_filter.observe(update_display, names=\"value\")\n",
        "\n",
        "refresh_domain_options_widget()\n",
        "\n",
        "filters[\"query_text\"].description = \"Prompt search:\"\n",
        "filters[\"message_text\"].description = \"Message search:\"\n",
        "\n",
        "for control in (domain_dropdown, domain_search, page_search, output_text_filter, filters[\"query_text\"], filters[\"message_text\"]):\n",
        "    control.style = {\"description_width\": \"150px\"}\n",
        "    control.layout = widgets.Layout(width=\"300px\")\n",
        "\n",
        "controls = widgets.VBox(\n",
        "    [\n",
        "        widgets.HBox(\n",
        "            [refresh_button, rebuild_button, export_table_button, export_view_button, export_highlights_button],\n",
        "            layout=widgets.Layout(margin=\"0 0 10px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [filters[\"scenario\"], filters[\"role\"], filters[\"persona\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [filters[\"model\"], filters[\"execution\"], filters[\"country\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [filters[\"query_dropdown\"], filters[\"query_text\"], filters[\"message_text\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [domain_dropdown, domain_search, page_search],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [output_text_filter, filters[\"unit\"], filters[\"turn\"], filters[\"citations_only\"], filters[\"rows\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [sort_column, sort_order],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "    ],\n",
        "    layout=widgets.Layout(width=\"100%\"),\n",
        ")\n",
        "\n",
        "status_box = widgets.VBox([message_output, download_link_html], layout=widgets.Layout(width=\"100%\"))\n",
        "app_layout = widgets.VBox(\n",
        "    [heading_html, controls, column_picker, summary_output, table_header, table_output, status_box],\n",
        "    layout=widgets.Layout(width=\"100%\"),\n",
        ")\n",
        "\n",
        "display(app_layout)\n",
        "update_display()\n"
      ],
      "id": "hAH9iaISScGv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wQq4FimScGw"
      },
      "source": [
        "# Analysis Step 4: Create a Report Grouped by Your Prompts\n",
        "This report flips the analysis around. Instead of focusing on the citations, it organizes the results based on the questions you asked. It lets you easily review all the different sources that were returned for each prompt you entered.\n",
        "\n",
        "### Using the Filters\n",
        "Use the filters to select a specific prompt you want to investigate, or filter by a keyword to see a group of related prompts.\n",
        "\n",
        "### Report Metrics Guide\n",
        "Here‚Äôs a guide to what each column in the report means:\n",
        "\n",
        "- **Prompt**: The exact text of the prompt you ran.\n",
        "- **Total Runs**: The number of times you ran this prompt.\n",
        "- **Total Citations**: The total number of citations generated across all runs of this prompt.\n",
        "- **Unique Citations**: The number of unique URLs cited for this prompt. A big difference between total and unique citations means the same URLs were cited repeatedly.\n",
        "- **Unique Domains**: The number of unique websites cited for this prompt.\n",
        "- **Avg. Citations per Run**: The average number of sources the AI provided each time you ran the prompt.\n",
        "- **Top Cited Domain**: The website that appeared most frequently as a source for this prompt.\n",
        "- **Top Cited Article**: The specific article URL that appeared most frequently for this prompt.\n"
      ],
      "id": "8wQq4FimScGw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBqUe67OScGw"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title Prompt-Level Insights Report (Cell 11d)\n",
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from urllib.parse import unquote, urlparse\n",
        "import sys\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "try:\n",
        "    refresh_master_df\n",
        "    create_filter_panel\n",
        "    apply_filters\n",
        "    export_dataframe\n",
        "    normalize_role_labels\n",
        "except NameError as exc:  # pragma: no cover - notebook guard\n",
        "    raise RuntimeError(\"Run Cell 11a first to load master dataset helpers.\") from exc\n",
        "\n",
        "\n",
        "AI_ROLE = globals().get(\"AI_ROLE_LABEL\", \"AI System\")\n",
        "\n",
        "\n",
        "REPORT_COLUMNS = [\n",
        "    \"Prompt Text\",\n",
        "    \"Scenario\",\n",
        "    \"Persona\",\n",
        "    \"Model\",\n",
        "    \"Total Prompt Runs\",\n",
        "    \"Unique Prompt Runs\",\n",
        "    \"% of Total Prompt Runs\",\n",
        "    \"Total Outputs\",\n",
        "    \"% of Outputs with Citations\",\n",
        "    \"Prompt Last Seen\",\n",
        "    \"Domain\",\n",
        "    \"Page Title\",\n",
        "    \"Unique Pages Cited\",\n",
        "    \"Full URL\",\n",
        "    \"Total Domain Citations\",\n",
        "    \"Total Page Citations\",\n",
        "    \"Avg Domain Rank\",\n",
        "    \"Avg Page Rank\",\n",
        "    \"% of Prompt Runs Citing Domain\",\n",
        "    \"% of Prompt Runs Citing Page\",\n",
        "    \"% of Outputs Citing Domain\",\n",
        "    \"% of Outputs Citing Page\",\n",
        "    \"Avg Citations per Output (Domain)\",\n",
        "    \"Avg Citations per Output (Page)\",\n",
        "    \"Recent Domain Velocity\",\n",
        "    \"First Seen Timestamp\",\n",
        "    \"Predictability Score\",\n",
        "    \"Page Last Seen Timestamp\",\n",
        "    \"Topical Authority Score\",\n",
        "    \"Days Since Last Seen\",\n",
        "]\n",
        "\n",
        "SORT_OPTIONS = [\n",
        "    (\"Prompt Text (A-Z)\", \"Prompt Text\"),\n",
        "    (\"Domain (A-Z)\", \"Domain\"),\n",
        "    (\"Average Domain Rank\", \"Avg Domain Rank\"),\n",
        "    (\"Average Page Rank\", \"Avg Page Rank\"),\n",
        "    (\"Domain Citations\", \"Total Domain Citations\"),\n",
        "    (\"Page Citations\", \"Total Page Citations\"),\n",
        "    (\"Predictability Score\", \"Predictability Score\"),\n",
        "    (\"Topical Authority Score\", \"Topical Authority Score\"),\n",
        "    (\"Recent Domain Velocity\", \"Recent Domain Velocity\"),\n",
        "    (\"% Prompt Runs (Domain)\", \"% of Prompt Runs Citing Domain\"),\n",
        "    (\"% Prompt Runs (Page)\", \"% of Prompt Runs Citing Page\"),\n",
        "]\n",
        "\n",
        "LAST_REPORT = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "LAST_VIEW = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "\n",
        "\n",
        "def clean_url(url: str) -> str:\n",
        "    if not isinstance(url, str):\n",
        "        return \"\"\n",
        "    sanitized = url.strip()\n",
        "    if not sanitized:\n",
        "        return \"\"\n",
        "    if \"?utm_\" in sanitized:\n",
        "        sanitized = sanitized.split(\"?utm_\")[0]\n",
        "    return sanitized\n",
        "\n",
        "\n",
        "def extract_domain(url: str) -> str:\n",
        "    parsed = urlparse(url)\n",
        "    netloc = parsed.netloc.replace(\"www.\", \"\")\n",
        "    return netloc or parsed.path or url\n",
        "\n",
        "\n",
        "def derive_title_from_url(url: str) -> str:\n",
        "    parsed = urlparse(url)\n",
        "    slug = unquote(Path(parsed.path).name or parsed.netloc or url)\n",
        "    normalized = slug.replace(\"-\", \" \").replace(\"_\", \" \").strip()\n",
        "    if not normalized:\n",
        "        return extract_domain(url)\n",
        "    return normalized.title()\n",
        "\n",
        "\n",
        "def derive_run_id(row: pd.Series) -> str:\n",
        "    exec_id = row.get(\"execution_id\") or \"exec\"\n",
        "    turn = row.get(\"turn_or_run\")\n",
        "    if pd.isna(turn) or turn == \"\":\n",
        "        turn = row.get(\"unit_id\") or \"unit\"\n",
        "    return f\"{exec_id}|{turn}\"\n",
        "\n",
        "\n",
        "def derive_prompt_run_id(row: pd.Series) -> str:\n",
        "    unit = row.get(\"unit_id\")\n",
        "    if pd.notna(unit) and unit != \"\":\n",
        "        return str(unit)\n",
        "    return row.get(\"run_id\") or derive_run_id(row)\n",
        "\n",
        "\n",
        "def format_timestamp_short(value: object) -> str:\n",
        "    if value in (None, \"\", \"NaT\"):\n",
        "        return \"\"\n",
        "    ts = pd.to_datetime(value, errors=\"coerce\", utc=True)\n",
        "    if pd.isna(ts):\n",
        "        return \"\"\n",
        "    return ts.tz_convert(\"UTC\").strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "\n",
        "def format_numeric(value: object, decimals: int = 2) -> str:\n",
        "    if pd.isna(value):\n",
        "        return \"\"\n",
        "    return f\"{float(value):.{decimals}f}\"\n",
        "\n",
        "\n",
        "def compute_topical_authority_score(prompt_pct: float, avg_rank: float | None) -> float:\n",
        "    if avg_rank is None or pd.isna(avg_rank):\n",
        "        rank_component = 50.0\n",
        "    else:\n",
        "        rank_component = max(0.0, (10 - min(avg_rank, 10)) / 9 * 100)\n",
        "    return (prompt_pct + rank_component) / 2\n",
        "\n",
        "\n",
        "def first_non_null(series: pd.Series) -> object:\n",
        "    if series is None or series.empty:\n",
        "        return None\n",
        "    non_null = series.dropna()\n",
        "    if non_null.empty:\n",
        "        return None\n",
        "    return non_null.iloc[0]\n",
        "\n",
        "\n",
        "def truncate_prompt_text(value: object, limit: int = 140) -> str:\n",
        "    if not isinstance(value, str):\n",
        "        return \"\" if value is None else str(value)\n",
        "    text = value.strip()\n",
        "    if len(text) <= limit:\n",
        "        return text\n",
        "    return text[: limit - 1].rstrip() + \"‚Ä¶\"\n",
        "\n",
        "\n",
        "def format_domain_link(domain: str) -> str:\n",
        "    if not isinstance(domain, str) or not domain:\n",
        "        return \"\"\n",
        "    return f'<a href=\"https://{domain}\" target=\"_blank\">{domain}</a>'\n",
        "\n",
        "\n",
        "def format_page_title_link(title: str, url: str) -> str:\n",
        "    if not isinstance(url, str) or not url:\n",
        "        return title or \"\"\n",
        "    safe_title = title or derive_title_from_url(url)\n",
        "    return f'<a href=\"{url}\" target=\"_blank\">{safe_title}</a>'\n",
        "\n",
        "\n",
        "def format_url_link(url: str) -> str:\n",
        "    if not isinstance(url, str) or not url:\n",
        "        return \"\"\n",
        "    return f'<a href=\"{url}\" target=\"_blank\">{url}</a>'\n",
        "\n",
        "\n",
        "def _build_domain_options(df: pd.DataFrame) -> list[str]:\n",
        "    if df.empty or \"citation_url\" not in df.columns:\n",
        "        return [\"All\"]\n",
        "    domains = {\n",
        "        extract_domain(clean_url(url))\n",
        "        for url in df[\"citation_url\"].dropna()\n",
        "        if isinstance(url, str) and clean_url(url)\n",
        "    }\n",
        "    return [\"All\"] + sorted(domains)\n",
        "\n",
        "\n",
        "POTENTIAL_OUTPUT_COLUMNS = [\n",
        "    \"message_text\",\n",
        "    \"assistant_response\",\n",
        "    \"model_response\",\n",
        "    \"response_text\",\n",
        "    \"citation_title\",\n",
        "    \"citation_text\",\n",
        "    \"query_or_topic\",\n",
        "]\n",
        "\n",
        "\n",
        "def build_prompt_insights(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    if df.empty:\n",
        "        empty = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "        return empty, empty\n",
        "\n",
        "    working = df[df[\"role\"] == AI_ROLE].copy()\n",
        "    if working.empty:\n",
        "        empty = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "        return empty, empty\n",
        "    working[\"query_or_topic\"] = working[\"query_or_topic\"].fillna(\"Unknown prompt\")\n",
        "    working[\"row_timestamp\"] = pd.to_datetime(working[\"row_timestamp\"], errors=\"coerce\", utc=True)\n",
        "    working[\"run_id\"] = working.apply(derive_run_id, axis=1)\n",
        "    working[\"prompt_run_id\"] = working.apply(derive_prompt_run_id, axis=1)\n",
        "\n",
        "    citations = working.dropna(subset=[\"citation_url\"]).copy()\n",
        "    if citations.empty:\n",
        "        return pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "\n",
        "    citations[\"clean_url\"] = citations[\"citation_url\"].apply(clean_url)\n",
        "    citations = citations[citations[\"clean_url\"] != \"\"]\n",
        "    if citations.empty:\n",
        "        return pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "\n",
        "    citations[\"domain\"] = citations[\"clean_url\"].apply(extract_domain)\n",
        "    citations = citations[citations[\"domain\"] != \"\"]\n",
        "    if citations.empty:\n",
        "        return pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "\n",
        "    citations[\"citation_rank\"] = pd.to_numeric(citations[\"citation_rank\"], errors=\"coerce\")\n",
        "    citations[\"page_title\"] = citations.apply(\n",
        "        lambda row: row[\"citation_title\"] if isinstance(row[\"citation_title\"], str) and row[\"citation_title\"].strip()\n",
        "        else derive_title_from_url(row[\"clean_url\"]),\n",
        "        axis=1,\n",
        "    )\n",
        "\n",
        "    now_ts = pd.Timestamp.utcnow()\n",
        "    if now_ts.tzinfo is None:\n",
        "        now_ts = now_ts.tz_localize(\"UTC\")\n",
        "    else:\n",
        "        now_ts = now_ts.tz_convert(\"UTC\")\n",
        "    window_start = now_ts - pd.Timedelta(days=7)\n",
        "    total_prompt_runs_all = max(working[\"prompt_run_id\"].nunique(), 1)\n",
        "\n",
        "    domain_records: list[dict[str, object]] = []\n",
        "    page_records: list[dict[str, object]] = []\n",
        "    prompt_groups = working.groupby(\"query_or_topic\")\n",
        "\n",
        "    for prompt, prompt_rows in prompt_groups:\n",
        "        prompt_total_runs = prompt_rows[\"prompt_run_id\"].nunique()\n",
        "        prompt_total_outputs = prompt_rows[\"run_id\"].nunique()\n",
        "        prompt_citations = citations[citations[\"query_or_topic\"] == prompt]\n",
        "        if prompt_citations.empty:\n",
        "            continue\n",
        "\n",
        "        prompt_citing_runs = prompt_citations[\"prompt_run_id\"].nunique()\n",
        "        outputs_with_cites = prompt_citations[\"run_id\"].nunique()\n",
        "        prompt_last_seen = prompt_citations[\"row_timestamp\"].max()\n",
        "\n",
        "        scenario = first_non_null(prompt_rows[\"scenario\"]) if \"scenario\" in prompt_rows.columns else None\n",
        "        persona = first_non_null(prompt_rows[\"persona_profile\"]) if \"persona_profile\" in prompt_rows.columns else None\n",
        "        model = first_non_null(prompt_rows[\"model\"]) if \"model\" in prompt_rows.columns else None\n",
        "\n",
        "        prompt_row_base = {\n",
        "            \"Prompt Text\": prompt,\n",
        "            \"Scenario\": scenario,\n",
        "            \"Persona\": persona,\n",
        "            \"Model\": model,\n",
        "            \"Total Prompt Runs\": prompt_total_runs,\n",
        "            \"Unique Prompt Runs\": prompt_citing_runs,\n",
        "            \"% of Total Prompt Runs\": (prompt_total_runs / total_prompt_runs_all) * 100,\n",
        "            \"Total Outputs\": prompt_total_outputs,\n",
        "            \"% of Outputs with Citations\": (outputs_with_cites / max(prompt_total_outputs, 1)) * 100,\n",
        "            \"Prompt Last Seen\": prompt_last_seen.isoformat() if pd.notna(prompt_last_seen) else None,\n",
        "        }\n",
        "\n",
        "        for domain, domain_rows in prompt_citations.groupby(\"domain\"):\n",
        "            domain_unique_pages = domain_rows[\"clean_url\"].nunique()\n",
        "            domain_total_cites = int(domain_rows.shape[0])\n",
        "            domain_avg_rank = domain_rows[\"citation_rank\"].mean() if not domain_rows[\"citation_rank\"].dropna().empty else None\n",
        "            domain_prompt_runs = domain_rows[\"prompt_run_id\"].nunique()\n",
        "            domain_outputs = domain_rows[\"run_id\"].nunique()\n",
        "\n",
        "            pct_prompt_runs_domain = (domain_prompt_runs / max(prompt_total_runs, 1)) * 100\n",
        "            pct_outputs_domain = (domain_outputs / max(prompt_total_outputs, 1)) * 100\n",
        "            avg_cites_per_output_domain = domain_total_cites / max(domain_outputs, 1)\n",
        "            domain_top3_pct = (\n",
        "                float((domain_rows[\"citation_rank\"] <= 3).mean() * 100)\n",
        "                if domain_rows[\"citation_rank\"].notna().any()\n",
        "                else 0.0\n",
        "            )\n",
        "            timestamps = domain_rows[\"row_timestamp\"].dropna()\n",
        "            recent_count = int((timestamps >= window_start).sum())\n",
        "            recent_velocity = (recent_count / domain_total_cites) * 100 if domain_total_cites else 0.0\n",
        "            predictability_score = (pct_outputs_domain + domain_top3_pct) / 2\n",
        "            topical_authority_score = compute_topical_authority_score(pct_prompt_runs_domain, domain_avg_rank)\n",
        "            domain_first_seen = timestamps.min()\n",
        "            domain_last_seen = timestamps.max()\n",
        "            domain_days_since_last = (now_ts - domain_last_seen).days if pd.notna(domain_last_seen) else None\n",
        "\n",
        "            domain_base = {\n",
        "                **prompt_row_base,\n",
        "                \"Domain\": domain,\n",
        "                \"Unique Pages Cited\": domain_unique_pages,\n",
        "                \"Total Domain Citations\": domain_total_cites,\n",
        "                \"Avg Domain Rank\": domain_avg_rank,\n",
        "                \"% of Prompt Runs Citing Domain\": pct_prompt_runs_domain,\n",
        "                \"% of Outputs Citing Domain\": pct_outputs_domain,\n",
        "                \"Avg Citations per Output (Domain)\": avg_cites_per_output_domain,\n",
        "                \"Recent Domain Velocity\": recent_velocity,\n",
        "                \"Predictability Score\": predictability_score,\n",
        "                \"Topical Authority Score\": topical_authority_score,\n",
        "                \"First Seen Timestamp\": domain_first_seen.isoformat() if pd.notna(domain_first_seen) else None,\n",
        "                \"Page Last Seen Timestamp\": domain_last_seen.isoformat() if pd.notna(domain_last_seen) else None,\n",
        "                \"Days Since Last Seen\": domain_days_since_last,\n",
        "            }\n",
        "\n",
        "            domain_record = {\n",
        "                **domain_base,\n",
        "                \"Page Title\": None,\n",
        "                \"Full URL\": None,\n",
        "                \"Total Page Citations\": None,\n",
        "                \"Avg Page Rank\": None,\n",
        "                \"% of Prompt Runs Citing Page\": None,\n",
        "                \"% of Outputs Citing Page\": None,\n",
        "                \"Avg Citations per Output (Page)\": None,\n",
        "            }\n",
        "            domain_records.append(domain_record)\n",
        "\n",
        "            for page_url, page_rows in domain_rows.groupby(\"clean_url\"):\n",
        "                page_total_cites = int(page_rows.shape[0])\n",
        "                page_avg_rank = page_rows[\"citation_rank\"].mean() if not page_rows[\"citation_rank\"].dropna().empty else None\n",
        "                page_prompt_runs = page_rows[\"prompt_run_id\"].nunique()\n",
        "                page_outputs = page_rows[\"run_id\"].nunique()\n",
        "                pct_prompt_runs_page = (page_prompt_runs / max(prompt_total_runs, 1)) * 100\n",
        "                pct_outputs_page = (page_outputs / max(prompt_total_outputs, 1)) * 100\n",
        "                avg_cites_per_output_page = page_total_cites / max(page_outputs, 1)\n",
        "                page_first_seen = page_rows[\"row_timestamp\"].min()\n",
        "                page_last_seen = page_rows[\"row_timestamp\"].max()\n",
        "                days_since_last = (now_ts - page_last_seen).days if pd.notna(page_last_seen) else None\n",
        "                page_title = page_rows[\"page_title\"].dropna().iloc[0]\n",
        "\n",
        "                record = {\n",
        "                    **domain_base,\n",
        "                    \"Page Title\": page_title,\n",
        "                    \"Full URL\": page_url,\n",
        "                    \"Total Page Citations\": page_total_cites,\n",
        "                    \"Avg Page Rank\": page_avg_rank,\n",
        "                    \"% of Prompt Runs Citing Page\": pct_prompt_runs_page,\n",
        "                    \"% of Outputs Citing Page\": pct_outputs_page,\n",
        "                    \"Avg Citations per Output (Page)\": avg_cites_per_output_page,\n",
        "                    \"First Seen Timestamp\": page_first_seen.isoformat() if pd.notna(page_first_seen) else None,\n",
        "                    \"Page Last Seen Timestamp\": page_last_seen.isoformat() if pd.notna(page_last_seen) else None,\n",
        "                    \"Days Since Last Seen\": days_since_last,\n",
        "                }\n",
        "                page_records.append(record)\n",
        "\n",
        "    if not page_records and not domain_records:\n",
        "        empty = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "        return empty, empty\n",
        "\n",
        "    domain_df = pd.DataFrame(domain_records, columns=REPORT_COLUMNS) if domain_records else pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "    page_df = pd.DataFrame(page_records, columns=REPORT_COLUMNS) if page_records else pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "    return domain_df, page_df\n",
        "\n",
        "\n",
        "def apply_custom_filters(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    working = df.copy()\n",
        "    if \"citation_url\" in working.columns:\n",
        "        working[\"__domain\"] = working[\"citation_url\"].apply(\n",
        "            lambda url: extract_domain(clean_url(url)) if isinstance(url, str) else \"\"\n",
        "        )\n",
        "    else:\n",
        "        working[\"__domain\"] = \"\"\n",
        "\n",
        "    if domain_dropdown.value != \"All\":\n",
        "        working = working[working[\"__domain\"] == domain_dropdown.value]\n",
        "\n",
        "    domain_contains = domain_search.value.strip().lower()\n",
        "    if domain_contains:\n",
        "        working = working[working[\"__domain\"].str.contains(domain_contains, case=False, na=False)]\n",
        "\n",
        "    page_contains = page_search.value.strip().lower()\n",
        "    if page_contains and \"citation_url\" in working.columns:\n",
        "        working = working[working[\"citation_url\"].astype(str).str.lower().str.contains(page_contains, na=False)]\n",
        "\n",
        "    output_contains = output_text_filter.value.strip().lower()\n",
        "    if output_contains:\n",
        "        mask = pd.Series(False, index=working.index)\n",
        "        for col in POTENTIAL_OUTPUT_COLUMNS:\n",
        "            if col in working.columns:\n",
        "                mask = mask | working[col].astype(str).str.lower().str.contains(output_contains, na=False)\n",
        "        if \"citation_url\" in working.columns:\n",
        "            mask = mask | working[\"citation_url\"].astype(str).str.lower().str.contains(output_contains, na=False)\n",
        "        working = working[mask]\n",
        "\n",
        "    return working.drop(columns=[\"__domain\"], errors=\"ignore\")\n",
        "\n",
        "\n",
        "def compute_summary(domain_df: pd.DataFrame, page_df: pd.DataFrame) -> dict[str, int | float]:\n",
        "    if domain_df.empty and page_df.empty:\n",
        "        return {\n",
        "            \"prompts\": 0,\n",
        "            \"domains\": 0,\n",
        "            \"pages\": 0,\n",
        "            \"total_citations\": 0,\n",
        "        }\n",
        "    return {\n",
        "        \"prompts\": domain_df[\"Prompt Text\"].nunique() if not domain_df.empty else page_df[\"Prompt Text\"].nunique(),\n",
        "        \"domains\": domain_df[\"Domain\"].nunique() if not domain_df.empty else 0,\n",
        "        \"pages\": page_df[\"Full URL\"].nunique() if not page_df.empty else 0,\n",
        "        \"total_citations\": int(page_df[\"Total Page Citations\"].sum()) if not page_df.empty and \"Total Page Citations\" in page_df else 0,\n",
        "    }\n",
        "\n",
        "\n",
        "master_df = normalize_role_labels(refresh_master_df(force_rebuild=False))\n",
        "filters = create_filter_panel(master_df)\n",
        "if \"role\" in filters and isinstance(filters[\"role\"], widgets.Widget):\n",
        "    role_options = getattr(filters[\"role\"], \"options\", [])\n",
        "    if isinstance(role_options, (list, tuple)) and AI_ROLE in role_options:\n",
        "        filters[\"role\"].value = AI_ROLE\n",
        "\n",
        "domain_dropdown = widgets.Dropdown(description=\"Domain:\", options=_build_domain_options(master_df), value=\"All\")\n",
        "domain_search = widgets.Text(description=\"Domain contains:\", placeholder=\"contains‚Ä¶\")\n",
        "page_search = widgets.Text(description=\"Page contains:\", placeholder=\"url or slug‚Ä¶\")\n",
        "output_text_filter = widgets.Text(description=\"Output text:\", placeholder=\"prompt/output contains‚Ä¶\")\n",
        "view_toggle = widgets.ToggleButtons(\n",
        "    description=\"View:\",\n",
        "    options=[(\"Domain + Page\", \"with_pages\"), (\"Domain only\", \"domain_only\")],\n",
        "    value=\"with_pages\",\n",
        ")\n",
        "\n",
        "DEFAULT_DISPLAY_COLUMNS = {\n",
        "    \"Prompt Text\",\n",
        "    \"Domain\",\n",
        "    \"Page Title\",\n",
        "    \"Model\",\n",
        "    \"Total Domain Citations\",\n",
        "    \"Total Page Citations\",\n",
        "    \"Avg Domain Rank\",\n",
        "    \"Avg Page Rank\",\n",
        "    \"Avg Citations per Output (Domain)\",\n",
        "    \"Avg Citations per Output (Page)\",\n",
        "}\n",
        "\n",
        "column_checkboxes = {\n",
        "    col: widgets.Checkbox(description=col, value=(col in DEFAULT_DISPLAY_COLUMNS))\n",
        "    for col in [\n",
        "        \"Prompt Text\",\n",
        "        \"Scenario\",\n",
        "        \"Persona\",\n",
        "        \"Model\",\n",
        "        \"Total Prompt Runs\",\n",
        "        \"Unique Prompt Runs\",\n",
        "        \"% of Total Prompt Runs\",\n",
        "        \"Total Outputs\",\n",
        "        \"% of Outputs with Citations\",\n",
        "        \"Prompt Last Seen\",\n",
        "        \"Domain\",\n",
        "        \"Page Title\",\n",
        "        \"Unique Pages Cited\",\n",
        "        \"Full URL\",\n",
        "        \"Total Domain Citations\",\n",
        "        \"Total Page Citations\",\n",
        "        \"Avg Domain Rank\",\n",
        "        \"Avg Page Rank\",\n",
        "        \"% of Prompt Runs Citing Domain\",\n",
        "        \"% of Prompt Runs Citing Page\",\n",
        "        \"% of Outputs Citing Domain\",\n",
        "        \"% of Outputs Citing Page\",\n",
        "        \"Avg Citations per Output (Domain)\",\n",
        "        \"Avg Citations per Output (Page)\",\n",
        "        \"Recent Domain Velocity\",\n",
        "        \"First Seen Timestamp\",\n",
        "        \"Predictability Score\",\n",
        "        \"Page Last Seen Timestamp\",\n",
        "        \"Topical Authority Score\",\n",
        "        \"Days Since Last Seen\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "column_picker_grid = widgets.GridBox(\n",
        "    list(column_checkboxes.values()),\n",
        "    layout=widgets.Layout(grid_template_columns=\"repeat(2, 50%)\", grid_gap=\"4px 12px\"),\n",
        ")\n",
        "column_picker_box = widgets.VBox([widgets.HTML(\"<b>Select columns to display:</b>\"), column_picker_grid])\n",
        "column_picker = widgets.Accordion(children=[column_picker_box])\n",
        "column_picker.set_title(0, \"+ Column picker\")\n",
        "column_picker.selected_index = None\n",
        "\n",
        "sort_column = widgets.Dropdown(description=\"Sort by:\", options=SORT_OPTIONS, value=\"Predictability Score\")\n",
        "sort_order = widgets.ToggleButtons(\n",
        "    description=\"Order:\",\n",
        "    options=[(\"Desc\", \"desc\"), (\"Asc\", \"asc\")],\n",
        "    value=\"desc\",\n",
        ")\n",
        "heading_html = widgets.HTML(\"<h3>Prompt-Level Insights Report</h3>\")\n",
        "refresh_button = widgets.Button(description=\"Refresh data\", icon=\"refresh\", button_style=\"primary\")\n",
        "rebuild_button = widgets.Button(description=\"Force rebuild\", icon=\"repeat\", button_style=\"danger\")\n",
        "export_table_button = widgets.Button(description=\"Export All\", icon=\"table\", button_style=\"warning\")\n",
        "export_view_button = widgets.Button(description=\"Export View\", icon=\"eye\", button_style=\"success\")\n",
        "export_highlights_button = widgets.Button(description=\"Export highlights\", icon=\"star\")\n",
        "export_highlights_button.style.button_color = \"#e0e0e0\"\n",
        "\n",
        "summary_output = widgets.Output()\n",
        "table_header = widgets.HTML(\"<h4>Prompt / Domain / Page performance</h4>\")\n",
        "table_output = widgets.Output(layout=widgets.Layout(max_height=\"520px\", overflow=\"auto\"))\n",
        "message_output = widgets.Output()\n",
        "download_link_html = widgets.HTML()\n",
        "\n",
        "\n",
        "def maybe_trigger_download(path: Path) -> None:\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        try:\n",
        "            from google.colab import files  # type: ignore\n",
        "\n",
        "            files.download(str(path))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "\n",
        "def sort_report(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "    ascending = sort_order.value == \"asc\"\n",
        "    return df.sort_values(sort_column.value, ascending=ascending)\n",
        "\n",
        "\n",
        "def update_display(_=None):\n",
        "    global LAST_REPORT, LAST_VIEW\n",
        "\n",
        "    filtered = apply_filters(master_df, filters)\n",
        "    filtered = apply_custom_filters(filtered)\n",
        "    domain_df, page_df = build_prompt_insights(filtered)\n",
        "    summary = compute_summary(domain_df, page_df)\n",
        "\n",
        "    with summary_output:\n",
        "        summary_output.clear_output()\n",
        "        display(HTML(\"<h4>Summary metrics</h4>\"))\n",
        "        if domain_df.empty and page_df.empty:\n",
        "            display(HTML(\"<p>No prompts with citations in the current view.</p>\"))\n",
        "            display(HTML(\"<br>\"))\n",
        "        else:\n",
        "            summary_df = pd.DataFrame(\n",
        "                [\n",
        "                    {\n",
        "                        \"Prompts w/ Citations\": f\"{summary['prompts']:,}\",\n",
        "                        \"Domains\": f\"{summary['domains']:,}\",\n",
        "                        \"Pages\": f\"{summary['pages']:,}\",\n",
        "                        \"Total Page Citations\": f\"{summary['total_citations']:,}\",\n",
        "                    }\n",
        "                ]\n",
        "            )\n",
        "            display(HTML(summary_df.to_html(index=False, escape=False)))\n",
        "        display(HTML(\"<br>\"))\n",
        "\n",
        "    with table_output:\n",
        "        table_output.clear_output()\n",
        "        active_df = domain_df if view_toggle.value == \"domain_only\" else page_df\n",
        "        if active_df.empty:\n",
        "            LAST_REPORT = pd.DataFrame(columns=REPORT_COLUMNS)\n",
        "            return\n",
        "\n",
        "        sorted_df = sort_report(active_df)\n",
        "        LAST_REPORT = sorted_df\n",
        "        rows = filters[\"rows\"].value\n",
        "        display_df = sorted_df.head(rows).copy()\n",
        "        LAST_VIEW = display_df.copy()\n",
        "\n",
        "        if \"Prompt Text\" in display_df.columns:\n",
        "            display_df[\"Prompt Text\"] = display_df[\"Prompt Text\"].apply(truncate_prompt_text)\n",
        "\n",
        "        if view_toggle.value == \"domain_only\":\n",
        "            for col in [\n",
        "                \"Page Title\",\n",
        "                \"Full URL\",\n",
        "                \"Total Page Citations\",\n",
        "                \"Avg Page Rank\",\n",
        "                \"% of Prompt Runs Citing Page\",\n",
        "                \"% of Outputs Citing Page\",\n",
        "                \"Avg Citations per Output (Page)\",\n",
        "                \"First Seen Timestamp\",\n",
        "                \"Page Last Seen Timestamp\",\n",
        "                \"Days Since Last Seen\",\n",
        "            ]:\n",
        "                if col in display_df.columns:\n",
        "                    display_df[col] = \"---\"\n",
        "\n",
        "        display_df[\"Domain\"] = display_df[\"Domain\"].apply(format_domain_link)\n",
        "        display_df[\"Page Title\"] = display_df.apply(\n",
        "            lambda row: format_page_title_link(row[\"Page Title\"], row[\"Full URL\"])\n",
        "            if isinstance(row[\"Page Title\"], str) and row[\"Page Title\"] not in (\"\", \"---\") and isinstance(row[\"Full URL\"], str) and row[\"Full URL\"] not in (\"\", \"---\")\n",
        "            else (row[\"Page Title\"] if isinstance(row[\"Page Title\"], str) else \"\"),\n",
        "            axis=1,\n",
        "        )\n",
        "        if \"Full URL\" in display_df.columns:\n",
        "            display_df[\"Full URL\"] = display_df[\"Full URL\"].apply(\n",
        "                lambda url: format_url_link(url) if isinstance(url, str) and url not in (\"\", \"---\") else url\n",
        "            )\n",
        "\n",
        "        percent_columns = [\n",
        "            \"% of Total Prompt Runs\",\n",
        "            \"% of Outputs with Citations\",\n",
        "            \"% of Prompt Runs Citing Domain\",\n",
        "            \"% of Prompt Runs Citing Page\",\n",
        "            \"% of Outputs Citing Domain\",\n",
        "            \"% of Outputs Citing Page\",\n",
        "            \"Recent Domain Velocity\",\n",
        "            \"Predictability Score\",\n",
        "            \"Topical Authority Score\",\n",
        "        ]\n",
        "        for col in percent_columns:\n",
        "            if col in display_df.columns:\n",
        "                display_df[col] = display_df[col].map(lambda v: f\"{format_numeric(v, 2)}%\" if pd.notna(v) and v != \"---\" else v)\n",
        "\n",
        "        numeric_columns = [\n",
        "            \"Avg Domain Rank\",\n",
        "            \"Avg Page Rank\",\n",
        "            \"Avg Citations per Output (Domain)\",\n",
        "            \"Avg Citations per Output (Page)\",\n",
        "        ]\n",
        "        for col in numeric_columns:\n",
        "            if col in display_df.columns:\n",
        "                display_df[col] = display_df[col].map(lambda v: format_numeric(v, 2) if pd.notna(v) and v != \"---\" else v)\n",
        "\n",
        "        timestamp_columns = [\n",
        "            \"Prompt Last Seen\",\n",
        "            \"First Seen Timestamp\",\n",
        "            \"Page Last Seen Timestamp\",\n",
        "        ]\n",
        "        for col in timestamp_columns:\n",
        "            if col in display_df.columns:\n",
        "                display_df[col] = display_df[col].map(\n",
        "                    lambda v: format_timestamp_short(v) if isinstance(v, str) and v != \"---\" else v\n",
        "                )\n",
        "\n",
        "        selected_columns = [col for col, checkbox in column_checkboxes.items() if checkbox.value]\n",
        "        if not selected_columns:\n",
        "            selected_columns = [col for col in REPORT_COLUMNS if col in DEFAULT_DISPLAY_COLUMNS] or REPORT_COLUMNS\n",
        "\n",
        "        valid_columns = [col for col in selected_columns if col in display_df.columns]\n",
        "        table_html = display_df[valid_columns].to_html(index=False, escape=False, classes=\"prompt-insights-table\")\n",
        "        styled_html = \"\"\"\n",
        "        <style>\n",
        "        .prompt-insights-table thead th {\n",
        "            position: sticky;\n",
        "            top: 0;\n",
        "            background: #f6f6f6;\n",
        "            z-index: 1;\n",
        "        }\n",
        "        .prompt-insights-table tbody td {\n",
        "            vertical-align: top;\n",
        "        }\n",
        "        </style>\n",
        "        \"\"\" + table_html\n",
        "        display(HTML(styled_html))\n",
        "\n",
        "\n",
        "def refresh_domain_options_widget() -> None:\n",
        "    options = _build_domain_options(master_df)\n",
        "    current = domain_dropdown.value if domain_dropdown.value in options else \"All\"\n",
        "    domain_dropdown.options = options\n",
        "    domain_dropdown.value = current\n",
        "\n",
        "\n",
        "def handle_refresh(_):\n",
        "    global master_df\n",
        "    master_df = normalize_role_labels(refresh_master_df(force_rebuild=False))\n",
        "    refresh_domain_options_widget()\n",
        "    update_display()\n",
        "\n",
        "\n",
        "def handle_rebuild(_):\n",
        "    global master_df\n",
        "    master_df = normalize_role_labels(refresh_master_df(force_rebuild=True))\n",
        "    refresh_domain_options_widget()\n",
        "    update_display()\n",
        "\n",
        "\n",
        "def handle_export_table(_):\n",
        "    if LAST_REPORT.empty:\n",
        "        with message_output:\n",
        "            message_output.clear_output()\n",
        "            print(\"‚ö†Ô∏è Nothing to export yet.\")\n",
        "        download_link_html.value = \"\"\n",
        "        return\n",
        "    path = export_dataframe(LAST_REPORT, \"prompt_insights_full\")\n",
        "    maybe_trigger_download(path)\n",
        "    with message_output:\n",
        "        message_output.clear_output()\n",
        "        print(\"üìÑ Exported full dataset.\")\n",
        "    download_link_html.value = f'<a href=\"{path}\" target=\"_blank\">Download CSV</a>'\n",
        "\n",
        "\n",
        "def handle_export_view(_):\n",
        "    if LAST_VIEW.empty:\n",
        "        with message_output:\n",
        "            message_output.clear_output()\n",
        "            print(\"‚ö†Ô∏è No filtered rows to export yet.\")\n",
        "        download_link_html.value = \"\"\n",
        "        return\n",
        "    path = export_dataframe(LAST_VIEW, \"prompt_insights_view\")\n",
        "    maybe_trigger_download(path)\n",
        "    with message_output:\n",
        "        message_output.clear_output()\n",
        "        print(\"üìÑ Exported current view.\")\n",
        "    download_link_html.value = f'<a href=\"{path}\" target=\"_blank\">Download CSV</a>'\n",
        "\n",
        "\n",
        "def handle_export_highlights(_):\n",
        "    if LAST_REPORT.empty:\n",
        "        with message_output:\n",
        "            message_output.clear_output()\n",
        "            print(\"‚ö†Ô∏è Nothing to export yet.\")\n",
        "        download_link_html.value = \"\"\n",
        "        return\n",
        "    df = LAST_REPORT\n",
        "    highlights = pd.concat(\n",
        "        [\n",
        "            df.nlargest(5, \"Predictability Score\").assign(Highlight=\"predictability_top5\"),\n",
        "            df.nlargest(5, \"Topical Authority Score\").assign(Highlight=\"authority_top5\"),\n",
        "            df.nlargest(5, \"Recent Domain Velocity\").assign(Highlight=\"velocity_top5\"),\n",
        "        ],\n",
        "        ignore_index=True,\n",
        "    ).drop_duplicates(subset=[\"Prompt Text\", \"Domain\", \"Full URL\", \"Highlight\"])\n",
        "    path = export_dataframe(highlights, \"prompt_insights_highlights\")\n",
        "    maybe_trigger_download(path)\n",
        "    with message_output:\n",
        "        message_output.clear_output()\n",
        "        print(\"üìÑ Highlight tables exported.\")\n",
        "    download_link_html.value = f'<a href=\"{path}\" target=\"_blank\">Download CSV</a>'\n",
        "\n",
        "\n",
        "refresh_button.on_click(handle_refresh)\n",
        "rebuild_button.on_click(handle_rebuild)\n",
        "export_table_button.on_click(handle_export_table)\n",
        "export_view_button.on_click(handle_export_view)\n",
        "export_highlights_button.on_click(handle_export_highlights)\n",
        "\n",
        "for widget in list(filters.values()) + [sort_column, sort_order, view_toggle]:\n",
        "    widget.observe(update_display, names=\"value\")\n",
        "\n",
        "for checkbox in column_checkboxes.values():\n",
        "    checkbox.observe(update_display, names=\"value\")\n",
        "\n",
        "\n",
        "def _sync_column_picker_title(change):\n",
        "    if change[\"name\"] == \"selected_index\":\n",
        "        column_picker.set_title(0, \"+ Column picker\" if change[\"new\"] is None else \"‚àí Column picker\")\n",
        "\n",
        "\n",
        "column_picker.observe(_sync_column_picker_title, names=\"selected_index\")\n",
        "\n",
        "domain_dropdown.observe(update_display, names=\"value\")\n",
        "domain_search.observe(update_display, names=\"value\")\n",
        "page_search.observe(update_display, names=\"value\")\n",
        "output_text_filter.observe(update_display, names=\"value\")\n",
        "\n",
        "filters[\"query_text\"].description = \"Prompt search:\"\n",
        "filters[\"message_text\"].description = \"Message search:\"\n",
        "\n",
        "for control in (\n",
        "    domain_dropdown,\n",
        "    domain_search,\n",
        "    page_search,\n",
        "    output_text_filter,\n",
        "    filters[\"query_text\"],\n",
        "    filters[\"message_text\"],\n",
        "):\n",
        "    control.style = {\"description_width\": \"150px\"}\n",
        "    control.layout = widgets.Layout(width=\"300px\")\n",
        "\n",
        "controls = widgets.VBox(\n",
        "    [\n",
        "        widgets.HBox(\n",
        "            [refresh_button, rebuild_button, export_table_button, export_view_button, export_highlights_button],\n",
        "            layout=widgets.Layout(margin=\"0 0 10px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [filters[\"scenario\"], filters[\"role\"], filters[\"persona\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [filters[\"model\"], filters[\"execution\"], filters[\"country\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [filters[\"query_dropdown\"], filters[\"query_text\"], filters[\"message_text\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [domain_dropdown, domain_search, page_search],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [output_text_filter, filters[\"unit\"], filters[\"turn\"], filters[\"citations_only\"], filters[\"rows\"]],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "        widgets.HBox(\n",
        "            [sort_column, sort_order, view_toggle],\n",
        "            layout=widgets.Layout(margin=\"0 0 6px 0\"),\n",
        "        ),\n",
        "    ],\n",
        "    layout=widgets.Layout(width=\"100%\"),\n",
        ")\n",
        "\n",
        "status_box = widgets.VBox([message_output, download_link_html], layout=widgets.Layout(width=\"100%\"))\n",
        "app_layout = widgets.VBox(\n",
        "    [heading_html, controls, column_picker, summary_output, table_header, table_output, status_box],\n",
        "    layout=widgets.Layout(width=\"100%\"),\n",
        ")\n",
        "\n",
        "display(app_layout)\n",
        "update_display()\n"
      ],
      "id": "XBqUe67OScGw"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}